{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ex01_mlp.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jan-kreischer/UZH_ML4NLP/blob/main/Project-01/ex01_mlp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5mUlNUnJ4Ljk"
      },
      "source": [
        "# Exercise 01 - Part 02"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-tSmGwauDkm"
      },
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DFdqlZ-1uDSw"
      },
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NfzPwQnN2eHY"
      },
      "source": [
        "## 1. Data Acquisition\n",
        "In this assignment we are not going to do all the data cleaning and preprocessing again.  \n",
        "We are just loading the saved dataset from the first exercise."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rPHMAkQcl6HA",
        "outputId": "c7995366-3419-4123-d2f4-cac620673127"
      },
      "source": [
        "!pip install demoji"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting demoji\n",
            "  Downloading demoji-1.1.0-py3-none-any.whl (42 kB)\n",
            "\u001b[?25l\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                        | 10 kB 15.8 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                | 20 kB 18.2 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ         | 30 kB 22.6 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 40 kB 16.1 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 42 kB 679 kB/s \n",
            "\u001b[?25hInstalling collected packages: demoji\n",
            "Successfully installed demoji-1.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CNaUC8y6JDVx",
        "outputId": "3f0b7126-89ec-49f6-92ee-0bc39a2906a9"
      },
      "source": [
        "!pip install googletrans==4.0.0rc1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting googletrans==4.0.0rc1\n",
            "  Downloading googletrans-4.0.0rc1.tar.gz (20 kB)\n",
            "Collecting httpx==0.13.3\n",
            "  Downloading httpx-0.13.3-py3-none-any.whl (55 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 55 kB 2.3 MB/s \n",
            "\u001b[?25hCollecting httpcore==0.9.*\n",
            "  Downloading httpcore-0.9.1-py3-none-any.whl (42 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 42 kB 1.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from httpx==0.13.3->googletrans==4.0.0rc1) (2021.5.30)\n",
            "Requirement already satisfied: idna==2.* in /usr/local/lib/python3.7/dist-packages (from httpx==0.13.3->googletrans==4.0.0rc1) (2.10)\n",
            "Collecting rfc3986<2,>=1.3\n",
            "  Downloading rfc3986-1.5.0-py2.py3-none-any.whl (31 kB)\n",
            "Collecting sniffio\n",
            "  Downloading sniffio-1.2.0-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: chardet==3.* in /usr/local/lib/python3.7/dist-packages (from httpx==0.13.3->googletrans==4.0.0rc1) (3.0.4)\n",
            "Collecting hstspreload\n",
            "  Downloading hstspreload-2021.10.1-py3-none-any.whl (1.2 MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.2 MB 27.7 MB/s \n",
            "\u001b[?25hCollecting h2==3.*\n",
            "  Downloading h2-3.2.0-py2.py3-none-any.whl (65 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 65 kB 3.0 MB/s \n",
            "\u001b[?25hCollecting h11<0.10,>=0.8\n",
            "  Downloading h11-0.9.0-py2.py3-none-any.whl (53 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 53 kB 1.8 MB/s \n",
            "\u001b[?25hCollecting hyperframe<6,>=5.2.0\n",
            "  Downloading hyperframe-5.2.0-py2.py3-none-any.whl (12 kB)\n",
            "Collecting hpack<4,>=3.0\n",
            "  Downloading hpack-3.0.0-py2.py3-none-any.whl (38 kB)\n",
            "Building wheels for collected packages: googletrans\n",
            "  Building wheel for googletrans (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for googletrans: filename=googletrans-4.0.0rc1-py3-none-any.whl size=17415 sha256=ab51c0e4dc37633575e4f28eb4253156e8a7e8ea46131278007b70852f53d617\n",
            "  Stored in directory: /root/.cache/pip/wheels/43/34/00/4fe71786ea6d12314b29037620c36d857e5d104ac2748bf82a\n",
            "Successfully built googletrans\n",
            "Installing collected packages: hyperframe, hpack, sniffio, h2, h11, rfc3986, httpcore, hstspreload, httpx, googletrans\n",
            "Successfully installed googletrans-4.0.0rc1 h11-0.9.0 h2-3.2.0 hpack-3.0.0 hstspreload-2021.10.1 httpcore-0.9.1 httpx-0.13.3 hyperframe-5.2.0 rfc3986-1.5.0 sniffio-1.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2aoiO-Esh19N"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LdOJGl6Gr07z"
      },
      "source": [
        "from io import StringIO\n",
        "import requests\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import warnings\n",
        "\n",
        "\n",
        "import csv\n",
        "import re\n",
        "import numpy as np\n",
        "\n",
        "import pandas as pd\n",
        "pd.set_option('display.max_rows', 200)  \n",
        "pd.set_option('display.max_columns', 200)   \n",
        "pd.set_option('display.width', 4000) \n",
        "\n",
        "\n",
        "import demoji\n",
        "\n",
        "from sklearn.utils import resample\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import classification_report\n",
        "from googletrans import Translator\n",
        "translator = Translator()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o8zj6rO6hKo2"
      },
      "source": [
        "url_train_dev = 'https://docs.google.com/spreadsheets/d/e/2PACX-1vTOZ2rC82rhNsJduoyKYTsVeH6ukd7Bpxvxn_afOibn3R-eadZGXu82eCU9IRpl4CK_gefEGsYrA_oM/pub?gid=1863430984&single=true&output=tsv'\n",
        "url_test = 'https://docs.google.com/spreadsheets/d/e/2PACX-1vT-KNR9nuYatLkSbzSRgpz6Ku1n4TN4w6kKmFLkA6QJHTfQzmX0puBsLF7PAAQJQAxUpgruDd_RRgK7/pub?gid=417546901&single=true&output=tsv'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fgLDtzKQ52IL"
      },
      "source": [
        "#translated_data = pd.read_pickle('sample_data/augmented_data.pkl')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RkIJ7QuNv_lt"
      },
      "source": [
        "### Constants"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DYruJqdrsPOS"
      },
      "source": [
        "TARGET_COLUMN = 'label'\n",
        "TWEET_COLUMN = 'tweet'\n",
        "SAMPLE_THRESHOLD = 20"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "okInclFn5rzc"
      },
      "source": [
        "### 1. Data Acquisition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SdwxfjxjhN58"
      },
      "source": [
        "def load_dataset(url):\n",
        "    r = requests.get(url)\n",
        "    data = r.content.decode('utf8')\n",
        "    df = pd.read_csv(StringIO(data), sep='\\t')\n",
        "    df.columns = ['tweet', 'label']\n",
        "    return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZmOiJT-2hPpt"
      },
      "source": [
        "training_data = load_dataset(url_train_dev)\n",
        "test_data = load_dataset(url_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LLhRDofrsShY"
      },
      "source": [
        "dataset = pd.concat([training_data, test_data], axis=0) # Merge into one dataset for the pre-processing"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rSWYkwJnsZ9h",
        "outputId": "ae20a38e-205a-4f63-fb95-a2e7396e9e4d"
      },
      "source": [
        "print(\"The length of the combined dataset is {0} training samples + {1} test samples = {2} samples\".format(len(training_data), len(test_data), len(dataset)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The length of the combined dataset is 52675 training samples + 13279 test samples = 65954 samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yJDwSNkfuMcE"
      },
      "source": [
        "dataset = dataset.sample(frac=1).reset_index(drop=True) # Randomly shuffle the data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 352
        },
        "id": "TvoAwKLCzd7N",
        "outputId": "71d1ade0-2084-4b53-81ac-506c525c21a8"
      },
      "source": [
        "dataset.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Anyone goin to the rope swing?</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>No fue fÃ¡cil pero valiÃ³ la pena.</td>\n",
              "      <td>es</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>@jochortega es plaga el lala jajajaja</td>\n",
              "      <td>es</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ç‰¹é€²ã®æ ¡èˆã®ãƒˆã‚¤ãƒ¬ã¯ã‚¦ã‚©ã‚·ãƒ¥ãƒ¬ãƒƒãƒˆãŒã¤ã„ã¦ã„ã¦ç¾¨ã¾ã—ã„</td>\n",
              "      <td>ja</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ë‘ ëˆˆì„ ê°ì€ ì´ìœ ê°€, ëˆ„êµ¬ë•Œë¬¸ë„ ì•„ë‹ˆê¸°ë¥¼...</td>\n",
              "      <td>ko</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Today stats: One follower, No unfollowers via ...</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Phone-hacking case shows openness is best poli...</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>@BlEBERSKING haha babyğŸ’•</td>\n",
              "      <td>und</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Brezilya artik sana aciyorum. :(</td>\n",
              "      <td>tr</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>@EmmaPereyraaa jajajaja ;)))))</td>\n",
              "      <td>und</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               tweet label\n",
              "0                     Anyone goin to the rope swing?    en\n",
              "1                   No fue fÃ¡cil pero valiÃ³ la pena.    es\n",
              "2              @jochortega es plaga el lala jajajaja    es\n",
              "3                        ç‰¹é€²ã®æ ¡èˆã®ãƒˆã‚¤ãƒ¬ã¯ã‚¦ã‚©ã‚·ãƒ¥ãƒ¬ãƒƒãƒˆãŒã¤ã„ã¦ã„ã¦ç¾¨ã¾ã—ã„    ja\n",
              "4                         ë‘ ëˆˆì„ ê°ì€ ì´ìœ ê°€, ëˆ„êµ¬ë•Œë¬¸ë„ ì•„ë‹ˆê¸°ë¥¼...    ko\n",
              "5  Today stats: One follower, No unfollowers via ...    en\n",
              "6  Phone-hacking case shows openness is best poli...    en\n",
              "7                            @BlEBERSKING haha babyğŸ’•   und\n",
              "8                   Brezilya artik sana aciyorum. :(    tr\n",
              "9                     @EmmaPereyraaa jajajaja ;)))))   und"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7OZ3EaAQ6Ahq"
      },
      "source": [
        "### 2. Data Exploration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "heZh4YHxhhQA"
      },
      "source": [
        "def data_exploration(df):\n",
        "  n_labels = len(np.unique(df[\"label\"]))\n",
        "  df = df.sort_values('label')\n",
        "  print(\"Dataset contains the columns: {}\".format(list(df.keys())))\n",
        "  print(\"with a total of {} observations\".format(len(df)))\n",
        "  print(\"and {} different possible labels.\".format(n_labels))\n",
        "  print(\"The unique labels are {}\".format(df[\"label\"].unique()))\n",
        "  plt.figure(figsize=(15, 3))\n",
        "  plt.hist(df[\"label\"], bins=n_labels)\n",
        "  plt.xticks(rotation=90)\n",
        "  plt.yscale(\"log\")\n",
        "  plt.xlabel(\"Language\")\n",
        "  plt.ylabel(\"#Occurences\")\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G4Z5fpaX76xr"
      },
      "source": [
        "def get_underrepresented_languages(df, target_column, sample_threshold):\n",
        "    df = df.groupby(target_column).size().to_frame().reset_index(drop=False).rename(columns={0: 'occurences'})\n",
        "    underrepresented_languages = list(df[df['occurences'] < SAMPLE_THRESHOLD][target_column])\n",
        "    return underrepresented_languages"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Syyazhl683ZK"
      },
      "source": [
        "def print_number_of_underrepresented_languages(df, target_column, sample_threshold):\n",
        "  underrepresented_languages = get_underrepresented_languages(df, target_column, sample_threshold)\n",
        "  print(\"There are {} languages in this data set with less then {} samples.\".format(len(underrepresented_languages), sample_threshold))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        },
        "id": "IZtCEi7_hYQW",
        "outputId": "e77197d7-ef9a-42f8-c00e-957f2b26e293"
      },
      "source": [
        "data_exploration(dataset)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset contains the columns: ['tweet', 'label']\n",
            "with a total of 65954 observations\n",
            "and 78 different possible labels.\n",
            "The unique labels are ['ar' 'ar_LATN' 'az' 'bg' 'bn' 'bs' 'ca' 'cs' 'cy' 'da' 'de' 'dv' 'el'\n",
            " 'en' 'es' 'et' 'eu' 'fa' 'fi' 'fr' 'gl' 'ha' 'he' 'hi' 'hi-Latn' 'hr'\n",
            " 'ht' 'hu' 'hy' 'id' 'is' 'it' 'ja' 'ja_LATN' 'jv' 'km' 'ko' 'ko_LATN'\n",
            " 'la' 'lv' 'mk' 'mn' 'mr' 'ms' 'ne' 'nl' 'no' 'pl' 'ps' 'ps_LATN' 'pt'\n",
            " 'ro' 'ru' 'si' 'sk' 'sl' 'sq' 'sr' 'su' 'sv' 'sw' 'ta' 'ta_LATN' 'th'\n",
            " 'tl' 'tn' 'tr' 'uk' 'und' 'ur' 'ur_LATN' 'vi' 'wo' 'xh' 'yo' 'zh-CN'\n",
            " 'zh-TW' 'zu']\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x216 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DLPZXkaLCH3s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa6662d7-6bf2-4d94-bd87-372c484a3661"
      },
      "source": [
        "print_number_of_underrepresented_languages(dataset, TARGET_COLUMN, SAMPLE_THRESHOLD)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 50 languages in this data set with less then 20 samples.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IYLOL2_B5OrT"
      },
      "source": [
        "### 3. Text Cleaning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "np67DQkz5JEm"
      },
      "source": [
        "This is generally a good idea as many text classification tools rely on counting the occurrences of words. If both upper and lower case versions of the same word are found in the text then the algorithm will count them as different words even though the meaning is the same. Of course this does mean that where the capitalised versions of a word exists, that does have a different meaning. For example the company Apple vs the fruit apple. This could result in poorer performance for some data sets. This is one area of NLP where you may try different methods to see how they affect the overall performance of the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vsh1XvSsAwYL"
      },
      "source": [
        "def remove_all_emojis(text):\n",
        "  dem = demoji.findall(text)\n",
        "  for item in dem.keys():\n",
        "    text = text.replace(item, '')\n",
        "  return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQfxTUB36n4C"
      },
      "source": [
        "def clean_data(df, column):\n",
        "    df = df.copy(deep=True) # Make deep copy of tweets\n",
        "    df[column] = df[column].str.lower() # Transform into all lowercase\n",
        "    \n",
        "    patterns = []\n",
        "    retweet_pattern = '^RT'\n",
        "    patterns.append(retweet_pattern)\n",
        "    xml_pattern = '&\\S+;'\n",
        "    patterns.append(xml_pattern)\n",
        "    hashtag_pattern = '#[A-Za-z0-9_]+'\n",
        "    patterns.append(hashtag_pattern)\n",
        "    twitter_mention_pattern = '@[A-Za-z0-9_]+'\n",
        "    patterns.append(twitter_mention_pattern)\n",
        "    http_pattern = 'http\\S+'\n",
        "    patterns.append(http_pattern)\n",
        "    www_pattern = 'www\\S+'\n",
        "    patterns.append(www_pattern)\n",
        "    tab_pattern = '\\t'\n",
        "    patterns.append(tab_pattern)\n",
        "    punctuation_pattern = '[!\"#$%&\\\\()*+,-./:;<=>?@\\[\\]^_`\\'{}~]+'\n",
        "    patterns.append(punctuation_pattern)\n",
        "    numeric_pattern = '[0-9]+'\n",
        "    patterns.append(numeric_pattern)\n",
        "    regex = \"|\".join(patterns)\n",
        "\n",
        "    #df[column] = df[column].apply(lambda elem: re.sub(r\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)|^rt|http.+?\", \"\", elem)) \n",
        "    df[column] = df[column].apply(lambda elem: re.sub(r\"{}\".format(regex), \"\", elem))\n",
        "    df[column] = df[column].apply(remove_all_emojis)\n",
        "    \n",
        "    return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JtIoEEyK8Dxx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be448858-f4be-45bd-d6d8-89873a0301da"
      },
      "source": [
        "# Now we want to find out which special characters need to be removed from tweets in order to make the prediction better.\n",
        "# We go over the printed list an not down the symbold which are not needed for language identification.\n",
        "# These will be removed in a later step.\n",
        "languages = list(np.unique(test_data['label']))\n",
        "for language in languages:\n",
        "  localized_tweets = training_data[training_data['label'] == language]\n",
        "  # Clean and compare them\n",
        "  cleaned_localized_tweets = clean_data(localized_tweets, 'tweet')\n",
        "  comparison_view = pd.concat([localized_tweets.drop(['label'], axis=1), cleaned_localized_tweets], axis=1)\n",
        "  print(comparison_view.head(5))\n",
        "  #print(localized_tweets.head(5))\n",
        "  print(\"---\")\n",
        "\n",
        "# Symbols like @<mention>, #, http://link !, numeric values (e.g 16000), \" do not help for language identification."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                               tweet                                              tweet label\n",
            "0  ÙŠØ§ Ù…Ù† Ø£Ù†Ø§Ø¯ÙŠÙ‡Ø§ ÙˆÙŠØ®Ù†Ù‚Ù†ÙŠ Ø§Ù„Ø¨ÙƒØ§Ø¡  ÙˆÙŠÙƒØ§Ø¯ ØµÙ…Øª Ø§Ù„Ø¯Ù…Ø¹ ...  ÙŠØ§ Ù…Ù† Ø£Ù†Ø§Ø¯ÙŠÙ‡Ø§ ÙˆÙŠØ®Ù†Ù‚Ù†ÙŠ Ø§Ù„Ø¨ÙƒØ§Ø¡  ÙˆÙŠÙƒØ§Ø¯ ØµÙ…Øª Ø§Ù„Ø¯Ù…Ø¹ ...    ar\n",
            "1  ÙÙŠÙ‡ ÙØ±Ù‚ Ø¨ÙŠÙ† Ø§Ù‡Ù„ ØºØ²Ø© Ø§Ù„Ù„Ù‰ Ù…Ø·Ø­ÙˆÙ†ÙŠÙ† Ù…Ù† Ù†Ø§Ø­ÙŠØªÙŠÙ† ÙˆØ¨...  ÙÙŠÙ‡ ÙØ±Ù‚ Ø¨ÙŠÙ† Ø§Ù‡Ù„ ØºØ²Ø© Ø§Ù„Ù„Ù‰ Ù…Ø·Ø­ÙˆÙ†ÙŠÙ† Ù…Ù† Ù†Ø§Ø­ÙŠØªÙŠÙ† ÙˆØ¨...    ar\n",
            "2  ï»‹ï»¦ ïºï»Ÿï» ïº¤ï»ˆïº” Ø§ï»Ÿïº¤ï» ï»®ïº“ïº“ ïºï»Ÿï» ï»² ïº‘ïº˜ï»ï»¤ïº¾ ï»“ï»´ï»¬ïº ï»‹ï»´ï»¨ï»´ï»š ïº‘ïº˜ï»”ï»œïº® ...  ï»‹ï»¦ ïºï»Ÿï» ïº¤ï»ˆïº” Ø§ï»Ÿïº¤ï» ï»®ïº“ïº“ ïºï»Ÿï» ï»² ïº‘ïº˜ï»ï»¤ïº¾ ï»“ï»´ï»¬ïº ï»‹ï»´ï»¨ï»´ï»š ïº‘ïº˜ï»”ï»œïº® ...    ar\n",
            "3                                  ÙŠØ§ Ø§Ø¨Ùˆ Ø³Ù„Ùˆ Ø¹Ø±ÙØªÙ†ÙŠ                                  ÙŠØ§ Ø§Ø¨Ùˆ Ø³Ù„Ùˆ Ø¹Ø±ÙØªÙ†ÙŠ    ar\n",
            "4  Ø¨50 Ø±ÙŠØ§Ù„ Ø£ÙƒÙÙ„ Ù…Ø¹ØªÙ…Ø± ÙÙŠ Ø±Ù…Ø¶Ø§Ù† ØŒ ÙˆÙ„Ùƒ Ø¨Ø¥Ø°Ù† Ø§Ù„Ù„Ù‡ Ù…...  Ø¨ Ø±ÙŠØ§Ù„ Ø£ÙƒÙÙ„ Ù…Ø¹ØªÙ…Ø± ÙÙŠ Ø±Ù…Ø¶Ø§Ù† ØŒ ÙˆÙ„Ùƒ Ø¨Ø¥Ø°Ù† Ø§Ù„Ù„Ù‡ Ù…Ø«Ù„...    ar\n",
            "---\n",
            "                                         tweet                            tweet    label\n",
            "2199                      ya allah ya allah x)              ya allah ya allah x  ar_LATN\n",
            "2200                   Ya rab tekhlas hel game          ya rab tekhlas hel game  ar_LATN\n",
            "2201                           Istaqfurullah ğŸ˜‚                   istaqfurullah   ar_LATN\n",
            "2202  @g56_ 7abeeebbbbbie enty ghalaaayyyy ğŸ˜©â¤ï¸   abeeebbbbbie enty ghalaaayyyy   ar_LATN\n",
            "2203    Ya Hasiib... Ya Jaliil... Ya Mujiib...    ya hasiib ya jaliil ya mujiib  ar_LATN\n",
            "---\n",
            "                                                  tweet                                              tweet label\n",
            "2211  GÃ¶zlÉ™mÉ™k sÉ™brin imtahanÄ±dÄ±r.Sevinc qapÄ±sÄ±nÄ±n a...  gÃ¶zlÉ™mÉ™k sÉ™brin imtahanÄ±dÄ±rsevinc qapÄ±sÄ±nÄ±n aÃ§...    az\n",
            "---\n",
            "                                                  tweet                                              tweet label\n",
            "2212  Ğ‘Ğ¾Ñ‚Ğ°Ñ Ğ¼Ğ¾Ğ¶Ğµ Ğ´Ğ° ÑÑ‚Ğ°Ğ½Ğµ Ğ¸Ğ·ĞºĞ»ÑÑ‡Ğ¸Ñ‚ĞµĞ»ĞµĞ½ Ğ¿Ğ¸Ğ»Ğ¾Ñ‚, ÑĞ¼ÑÑ‚Ğ° ...  Ğ±Ğ¾Ñ‚Ğ°Ñ Ğ¼Ğ¾Ğ¶Ğµ Ğ´Ğ° ÑÑ‚Ğ°Ğ½Ğµ Ğ¸Ğ·ĞºĞ»ÑÑ‡Ğ¸Ñ‚ĞµĞ»ĞµĞ½ Ğ¿Ğ¸Ğ»Ğ¾Ñ‚ ÑĞ¼ÑÑ‚Ğ° Ñ...    bg\n",
            "2213  ĞĞ°Ğ¹-Ğ´Ğ¾Ğ±Ñ€Ğµ ÑĞµ ÑĞ¼ĞµĞµ ,ĞºĞ¾Ğ¹Ñ‚Ğ¾ ÑĞµ ÑĞ¼ĞµĞµ Ğ¿Ğ¾ÑĞ»ĞµĞ´ĞµĞ½ --Ğ´Ğ½...  Ğ½Ğ°Ğ¹Ğ´Ğ¾Ğ±Ñ€Ğµ ÑĞµ ÑĞ¼ĞµĞµ ĞºĞ¾Ğ¹Ñ‚Ğ¾ ÑĞµ ÑĞ¼ĞµĞµ Ğ¿Ğ¾ÑĞ»ĞµĞ´ĞµĞ½ Ğ´Ğ½ĞµÑ Ğ¼...    bg\n",
            "---\n",
            "                                                  tweet                                              tweet label\n",
            "2222  Najbolji ğŸ’ŸğŸ’Ÿ blue angels berlin http://t.co/4wF...                      najbolji  blue angels berlin     bs\n",
            "2223  SubotiÄ‡ oslobodjen optuÅ¾bi za Å¡verc cigareta- ...      subotiÄ‡ oslobodjen optuÅ¾bi za Å¡verc cigareta     bs\n",
            "2224              @samobakrac u septembru ulaze u vlast                          u septembru ulaze u vlast    bs\n",
            "2225  Italijanski novinar Vanoli(70) upozorava: VAKC...  italijanski novinar vanoli upozorava vakcinama...    bs\n",
            "---\n",
            "                                                  tweet                                              tweet label\n",
            "2226  @Laureta8 a tu cariÃ±et dspues prlem molts besi...            a tu cariÃ±et dspues prlem molts besitos    ca\n",
            "2227  No en tinc ni idea Teresa @llobetilla, esperem...  no en tinc ni idea teresa  esperem que respong...    ca\n",
            "2228  Res es imposible. Ell m'ha ensenyat que si vol...  res es imposible ell mha ensenyat que si vols ...    ca\n",
            "2229                   @CescGF jaspi aventures mata! :)                              jaspi aventures mata     ca\n",
            "2230  @Somia_Truites Ets tot un caballer!!! I una mo...   ets tot un caballer i una molt bona persona a...    ca\n",
            "---\n",
            "                                                  tweet                                              tweet label\n",
            "2248  Mechanical Moth - Winternachtstraum texty a pÅ™...  mechanical moth  winternachtstraum texty a pÅ™e...    cs\n",
            "2249  Na NovotnÃ©ho lÃ¡vce jsou k vidÄ›nÃ­ Smetanovy kre...  na novotnÃ©ho lÃ¡vce jsou k vidÄ›nÃ­ smetanovy kre...    cs\n",
            "2250  #ojeu #notice 33115100 â‚¬521k ÄŒeskÃ½ Krumlov:CT ...     â‚¬k ÄeskÃ½ krumlovct skener dodÃ¡vka ct skener...    cs\n",
            "2251  Sestra nevÄ›sty mÃ¡ dle maminky dÅ¯leÅ¾itou Ãºlohu....  sestra nevÄ›sty mÃ¡ dle maminky dÅ¯leÅ¾itou Ãºlohu ...    cs\n",
            "---\n",
            "                                                  tweet                                              tweet label\n",
            "2253                           @UnibetNorge 2-1 til arg                                            til arg    da\n",
            "2254  Blank &amp; Jones - Fallen (Delerium &amp; Ran...  blank  jones  fallen delerium  rani sangtekste...    da\n",
            "2255         @jesperdahl @kaarelbk det er jo helt vildt                               det er jo helt vildt    da\n",
            "2256  @mpbdavidsen Jeg har nydt hvert et minut. Men ...   jeg har nydt hvert et minut men jeg fÃ¸ler ikk...    da\n",
            "2257  BB (Les) - Comme Un Loup sangtekster og oversÃ¦...  bb les  comme un loup sangtekster og oversÃ¦tte...    da\n",
            "---\n",
            "                                                  tweet                                              tweet label\n",
            "2260                @hmjahnel guten morgen, der herr :)                             guten morgen der herr     de\n",
            "2261  @SkaKeller @GreensEP @Piratenpartei @JanAlbrec...                                      wie peinlich     de\n",
            "2262  Ich habe 16,100 GoldmÃ¼nzen gesammelt! http://t...                 ich habe  goldmÃ¼nzen gesammelt        de\n",
            "2263  Dachte frÃ¼her immer es heiÃŸt \"Sommer Angebot\" ...  dachte frÃ¼her immer es heiÃŸt sommer angebot an...    de\n",
            "2264  Da kommt Bei mir ist es sau langsam; keine Sch...  da kommt bei mir ist es sau langsam keine schu...    de\n",
            "---\n",
            "                                                  tweet                                              tweet label\n",
            "2432  ÎŒÎ»Î± Î¾ÎµÎºÎ¹Î½Î¬Î½Îµ Î±Ï€ÏŒ Ï„Î¿Î½ Î±Î½ÏÏ€Î±ÏÎºÏ„Î¿ ÎµÏ€Î±Î³Î³ÎµÎ»Î¼Î±Ï„Î¹ÎºÏŒ Ï€...  ÏŒÎ»Î± Î¾ÎµÎºÎ¹Î½Î¬Î½Îµ Î±Ï€ÏŒ Ï„Î¿Î½ Î±Î½ÏÏ€Î±ÏÎºÏ„Î¿ ÎµÏ€Î±Î³Î³ÎµÎ»Î¼Î±Ï„Î¹ÎºÏŒ Ï€...    el\n",
            "2433  http://t.co/sLTRx7aTgP  #Bring1DToGreeceCampai...                                       Î´Î¹Î±ÎºÎ¿ÏƒÎ¹Î± Î¿Î»Îµ    el\n",
            "2434  ÎœÏ€Î±Î¯Î½ÎµÎ¹ ÎºÎ±Î¹ Ï€ÎµÏÏ€Î±Ï„Î¬ÎµÎ¹ ÎºÎ±Ï„ÏƒÎ±ÏÎ¯Î´Î± ÏƒÏ„Î¿ ÏƒÏ€Î¹Ï„Î¹ ÏƒÎ±Î½ ...  Î¼Ï€Î±Î¯Î½ÎµÎ¹ ÎºÎ±Î¹ Ï€ÎµÏÏ€Î±Ï„Î¬ÎµÎ¹ ÎºÎ±Ï„ÏƒÎ±ÏÎ¯Î´Î± ÏƒÏ„Î¿ ÏƒÏ€Î¹Ï„Î¹ ÏƒÎ±Î½ ...    el\n",
            "2435  @its_leonidas Î”ÎµÎ½ Î½Î¿Î¼Î¯Î¶Ï‰ Î½Î± Î­Ï‡ÎµÏ„Îµ Î»ÏŒÎ³Î¿ Î½Î± Ï„Î¿ Îº...   Î´ÎµÎ½ Î½Î¿Î¼Î¯Î¶Ï‰ Î½Î± Î­Ï‡ÎµÏ„Îµ Î»ÏŒÎ³Î¿ Î½Î± Ï„Î¿ ÎºÎ¬Î½ÎµÏ„Îµ Î¿ÏÏ„Îµ Î´Î¹...    el\n",
            "2436  Î Î±Î½Î·Î³Ï…ÏÎ¯Î¶ÎµÎ¹ ÎºÎ±Î¹ Î· Î”Î—ÎœÎ‘Î¡ Î³Î¹Î± Ï„Î·Î½ ÎµÏ€Î­Î»Î±ÏƒÎ· Ï„Ï‰Î½ Î¹Ïƒ...  Ï€Î±Î½Î·Î³Ï…ÏÎ¯Î¶ÎµÎ¹ ÎºÎ±Î¹ Î· Î´Î·Î¼Î±Ï Î³Î¹Î± Ï„Î·Î½ ÎµÏ€Î­Î»Î±ÏƒÎ· Ï„Ï‰Î½ Î¹Ïƒ...    el\n",
            "---\n",
            "                                                  tweet                                              tweet label\n",
            "2460  ÎŸÏ„Î±Î½ ÏŒÎ¼Ï‰Ï‚ ÎµÎ¯Î½Î±Î¹ Ï„Î¿ ÎºÏÎ¬Ï„Î¿Ï‚ Ï€Î¿Ï… ÎµÏ€Î¹Î²Î¬Î»Î»ÎµÎ¹ Î´Î¹Î¬ Î½ÏŒ...  Î¿Ï„Î±Î½ ÏŒÎ¼Ï‰Ï‚ ÎµÎ¯Î½Î±Î¹ Ï„Î¿ ÎºÏÎ¬Ï„Î¿Ï‚ Ï€Î¿Ï… ÎµÏ€Î¹Î²Î¬Î»Î»ÎµÎ¹ Î´Î¹Î¬ Î½ÏŒ...    en\n",
            "2461                             @Duaa_e_aamir  urself*                                             urself    en\n",
            "2462                               1/5 please #JulyWish                                            please     en\n",
            "2463                                           to happy                                           to happy    en\n",
            "2464      Wtfffff already a month of summer has gone by      wtfffff already a month of summer has gone by    en\n",
            "---\n",
            "                                                   tweet                                              tweet label\n",
            "20968  LAS EMOCIONES dependen del grado de: CANTIDAD,...  las emociones dependen del grado de cantidad c...    es\n",
            "20969  No pare un segundo en todo el dia, todavia me ...  no pare un segundo en todo el dia todavia me f...    es\n",
            "20970             Dios tu tienes algo preparado para myâ™¥              dios tu tienes algo preparado para my    es\n",
            "20971  si te haces el piercing en el labio y no te qu...  si te haces el piercing en el labio y no te qu...    es\n",
            "20972  Ahora en @AldeaLocalZte  hablamos de la creaci...  ahora en   hablamos de la creaciÃ³n de la parro...    es\n",
            "---\n",
            "Empty DataFrame\n",
            "Columns: [tweet, tweet, label]\n",
            "Index: []\n",
            "---\n",
            "                                                   tweet                                              tweet label\n",
            "26900  Ø±ÛŒÛŒØ³ ÙØ±Ø§Ú©Ø³ÛŒÙˆÙ† Ø²Ù†Ø§Ù† Ù…Ø¬Ù„Ø³ ØªÙ„ÙˆÛŒØ­Ø§ Ø¨Ù‡ ÙˆØ¬ÙˆØ¯ Ø­Ú©Ù… Ø­Ú©Ùˆ...  Ø±ÛŒÛŒØ³ ÙØ±Ø§Ú©Ø³ÛŒÙˆÙ† Ø²Ù†Ø§Ù† Ù…Ø¬Ù„Ø³ ØªÙ„ÙˆÛŒØ­Ø§ Ø¨Ù‡ ÙˆØ¬ÙˆØ¯ Ø­Ú©Ù… Ø­Ú©Ùˆ...    fa\n",
            "26901  Ø§ÙØ²Ø§ÛŒØ´ Û²Û° Ø¯Ø±ØµØ¯ÛŒ Ø´Ù…Ø§Ø± Ù…Ø¨ØªÙ„Ø§ÛŒØ§Ù† Ø¨Ù‡ ÙˆÛŒØ±ÙˆØ³ Ø§Ø¨ÙˆÙ„Ø§ Ø¯...  Ø§ÙØ²Ø§ÛŒØ´ Û²Û° Ø¯Ø±ØµØ¯ÛŒ Ø´Ù…Ø§Ø± Ù…Ø¨ØªÙ„Ø§ÛŒØ§Ù† Ø¨Ù‡ ÙˆÛŒØ±ÙˆØ³ Ø§Ø¨ÙˆÙ„Ø§ Ø¯...    fa\n",
            "26902  @farzi_mahdi @aydaezadi @mrdodel @pariart71 Ù¾Ø±...                              Ù¾Ø±ÙŠØ³Ø§Ø§Ø§ ØµØ¯Ø§Ø´ Ø¯Ø± Ù†Ù…ÙŠØ§Ø¯    fa\n",
            "26903  Ø¯Ø§Ù†Ù„ÙˆØ¯ The Ministry of Silly Walks 1.0.3 Ø¨Ø§Ø²ÛŒ ...  Ø¯Ø§Ù†Ù„ÙˆØ¯ the ministry of silly walks  Ø¨Ø§Ø²ÛŒ Ø§Ú©Ø´Ù† ...    fa\n",
            "26904                          @shavoor ØªÙ„Ø§Ø´ Ø®ÙˆØ¯Øª Ø±Ùˆ Ø¨Ú©Ù†                                   ØªÙ„Ø§Ø´ Ø®ÙˆØ¯Øª Ø±Ùˆ Ø¨Ú©Ù†    fa\n",
            "---\n",
            "                                                   tweet                                              tweet label\n",
            "26918  @HenriAlen TosielÃ¤mÃ¤n vÃ¤lipalaa miehellÃ¤ #kuit...     tosielÃ¤mÃ¤n vÃ¤lipalaa miehellÃ¤   terveellistÃ¤      fi\n",
            "26919  Miss mÃ¤rkÃ¤paita #mattopesulla #suomalainentrad...                          miss mÃ¤rkÃ¤paita   tÃ¤mÃ¤kin    fi\n",
            "26920  @Mirppu outoo vaa kuvitella ku et kÃ¤y enÃ¤Ã¤ bÃ¤k...        outoo vaa kuvitella ku et kÃ¤y enÃ¤Ã¤ bÃ¤kkÃ¤ril    fi\n",
            "26921  @anskiiuu Uskon! :D Mutt jokainen tsÃ¤Ã¤nssi on ...   uskon d mutt jokainen tsÃ¤Ã¤nssi on niille mahd...    fi\n",
            "26922  Jotenkin, ihan hitusen tosin, nÃ¤yttÃ¤isi siltÃ¤,...  jotenkin ihan hitusen tosin nÃ¤yttÃ¤isi siltÃ¤ et...    fi\n",
            "---\n",
            "                                                   tweet                                              tweet label\n",
            "26933                @Alicia_Mammola jte comprend ahah ğŸ’•                                 jte comprend ahah     fr\n",
            "26934  Je suis sur qui y'as plus de prÃ©vente a Black ...  je suis sur qui yas plus de prÃ©vente a black top     fr\n",
            "26935  @luke5sos hey bb Ã§a va tu t'amuse bien en boit...       hey bb Ã§a va tu tamuse bien en boite de nuit    fr\n",
            "26936  J'ai hÃ¢te qu'elle regarde jusqu'au bout  Bon j...  jai hÃ¢te quelle regarde jusquau bout  bon je v...    fr\n",
            "26937  Oklmzer le taf, petit bureau avec double scree...  oklmzer le taf petit bureau avec double screen...    fr\n",
            "---\n",
            "                                                   tweet                                       tweet label\n",
            "27883                               ××™×–×” ×”×¨×’×©×” ××¡×¨×™×—×”...                           ××™×–×” ×”×¨×’×©×” ××¡×¨×™×—×”    he\n",
            "27884                                  ××™×Ÿ ×”×™×•× ××©×—×§×§×§ ğŸ˜©                            ××™×Ÿ ×”×™×•× ××©×—×§×§×§     he\n",
            "27885  @LDJ_France @Tsahal_IDF @JuifIsrael @Tsipora77...                    shabbat shalom umevorakh    he\n",
            "27886  â€œ@ZoharHazani: â€œ@AMITELIYAO: â€œ@shiraz_nachmias...  â€œ â€œ â€œ ×—×™×™×‘×ª ×œ×œ×›×ª ×œ×¨××•×ª ××©××ª ×”×›×•×›×‘×™× ×©×•×‘â€â€â€    he\n",
            "27887                              @karin201020 × ×§×•×•×” ×©×œ                                    × ×§×•×•×” ×©×œ    he\n",
            "---\n",
            "                                                   tweet                                              tweet label\n",
            "27910  à¤•à¤¿à¤¸à¥‡ à¤¸à¥à¤¨à¤¾à¤à¤ à¤…à¤ªà¤¨à¥‡ à¤—à¤® à¤•à¥‡ à¤šà¤¨à¥à¤¦ à¤ªà¤¨à¥à¤¨à¥‹ à¤•à¥‡ à¤•à¤¿à¤¸à¥à¤¸à¥‡, à¤¯...  à¤•à¤¿à¤¸à¥‡ à¤¸à¥à¤¨à¤¾à¤à¤ à¤…à¤ªà¤¨à¥‡ à¤—à¤® à¤•à¥‡ à¤šà¤¨à¥à¤¦ à¤ªà¤¨à¥à¤¨à¥‹ à¤•à¥‡ à¤•à¤¿à¤¸à¥à¤¸à¥‡ à¤¯à¤¹...    hi\n",
            "27911  à¤­à¥‹à¤ªà¤¾à¤²-à¤°à¤¾à¤œà¥à¤¯à¤¸à¤­à¤¾ à¤¸à¤¾à¤‚à¤¸à¤¦ à¤…à¤¨à¤¿à¤² à¤¦à¤µà¥‡ à¤¦à¤¿à¤²à¥à¤²à¥€ à¤°à¤µà¤¾à¤¨à¤¾,à¤à¤¯à¤°...  à¤­à¥‹à¤ªà¤¾à¤²à¤°à¤¾à¤œà¥à¤¯à¤¸à¤­à¤¾ à¤¸à¤¾à¤‚à¤¸à¤¦ à¤…à¤¨à¤¿à¤² à¤¦à¤µà¥‡ à¤¦à¤¿à¤²à¥à¤²à¥€ à¤°à¤µà¤¾à¤¨à¤¾à¤à¤¯à¤° à¤‡...    hi\n",
            "27912  13/7 à¤®à¥à¤‚à¤¬à¤ˆ à¤§à¤®à¤¾à¤•à¥‹à¤‚ à¤•à¥‹ à¤²à¥‡à¤•à¤° à¤†à¤‚à¤¤à¤•à¥€ à¤­à¤Ÿà¤•à¤² à¤•à¥‹ à¤•à¥‹à¤ˆ à¤ªà¤›...   à¤®à¥à¤‚à¤¬à¤ˆ à¤§à¤®à¤¾à¤•à¥‹à¤‚ à¤•à¥‹ à¤²à¥‡à¤•à¤° à¤†à¤‚à¤¤à¤•à¥€ à¤­à¤Ÿà¤•à¤² à¤•à¥‹ à¤•à¥‹à¤ˆ à¤ªà¤›à¤¤à¤¾à¤µà¤¾...    hi\n",
            "27913        @sagornoyon70 à¦¨à§‡à¦¹à¦¿ à¦•à¦¾à¦° à¦ªà¦¾à¦“à¦—à§‡ ;) @ShManus786                                   à¦¨à§‡à¦¹à¦¿ à¦•à¦¾à¦° à¦ªà¦¾à¦“à¦—à§‡      hi\n",
            "27914  #RT #ipad #iphone à¤‡à¤°à¤¾à¤• à¤®à¥‡à¤‚ à¤…à¤ªà¤¨à¥‡ à¤¶à¤¿à¤¯à¤¾ à¤­à¤¾à¤‡à¤¯à¥‹à¤‚ à¤•à¥€...     à¤‡à¤°à¤¾à¤• à¤®à¥‡à¤‚ à¤…à¤ªà¤¨à¥‡ à¤¶à¤¿à¤¯à¤¾ à¤­à¤¾à¤‡à¤¯à¥‹à¤‚ à¤•à¥€ à¤®à¤¦à¤¦ à¤•à¥‡ à¤²à¤¿à¤ à¤œà¤¾à¤¨...    hi\n",
            "---\n",
            "                                                   tweet                                              tweet    label\n",
            "27926  rochi di kuch controversial hone pe apne aap o...  rochi di kuch controversial hone pe apne aap o...  hi-Latn\n",
            "27927  @Nilesh_Shah usse mil lijiye.. aapko b pta hai...   usse mil lijiye aapko b pta hai kiski baat kr...  hi-Latn\n",
            "27928    Yeh meri umar ne meri zindagi kharab kardi hai.     yeh meri umar ne meri zindagi kharab kardi hai  hi-Latn\n",
            "27929                                       Maa ki aankh                                       maa ki aankh  hi-Latn\n",
            "27930  mar jayiya tere bin  mar jayiya tere bin mar j...  mar jayiya tere bin  mar jayiya tere bin mar j...  hi-Latn\n",
            "---\n",
            "                                                   tweet                                              tweet label\n",
            "27941       Aa izgrickala sam sve nokte do zivca,umireem        aa izgrickala sam sve nokte do zivcaumireem    hr\n",
            "27942                     jebote pa muskarci nose suknje                     jebote pa muskarci nose suknje    hr\n",
            "27943  majka kaze da kad bih pojela vola ne bi mi se ...  majka kaze da kad bih pojela vola ne bi mi se ...    hr\n",
            "27944                   O, zasto smo sada toliko daleko?                     o zasto smo sada toliko daleko    hr\n",
            "27945                   @mlccs1 kuku znam tog lika .....                                kuku znam tog lika     hr\n",
            "---\n",
            "                                                   tweet                                              tweet label\n",
            "27946  Jan majorite moun ap viv Ayiti a RT @RomeroBou...  jan majorite moun ap viv ayiti a rt  kijan mou...    ht\n",
            "27947  Gwo vant pa alamod Ekri ou rele 37201033 mande...  gwo vant pa alamod ekri ou rele  mande pwodwi ...    ht\n",
            "---\n",
            "                                                   tweet                                              tweet label\n",
            "27965          disaat kita terlalu bergantung kepada org          disaat kita terlalu bergantung kepada org    id\n",
            "27966  Klo udh gk syg mndng tnggln aja drpda kek gni ...  klo udh gk syg mndng tnggln aja drpda kek gni ...    id\n",
            "27967                  Orang benar akan hidup oleh iman.                   orang benar akan hidup oleh iman    id\n",
            "27968                           @LarasNiaty_ Iyy dong :)                                          iyy dong     id\n",
            "27969  Woiiii @kasyfanzulamia @Aulia_Javadd @NurAdhin...      woiiii    kalian harus ikut bukber kita wajib    id\n",
            "---\n",
            "                                                   tweet                                              tweet label\n",
            "30972  Ti svegli e improvvisamente #sixseasonsandamov...                     ti svegli e improvvisamente       it\n",
            "30973  Enzo Salvi - \"Va va va\" E chi non la canta VAVAVA     enzo salvi  va va va e chi non la canta vavava    it\n",
            "30974  Claudio Vismara piÃ¹ che ted di how i met your ...  claudio vismara piÃ¹ che ted di how i met your ...    it\n",
            "30975  Il viaggio in progressione di Arno Cost &amp; ...  il viaggio in progressione di arno cost  norma...    it\n",
            "30976  SEI UN BEL PORCO IO SONO UNA TROIA IN CALORE (...  sei un bel porco io sono una troia in calore t...    it\n",
            "---\n",
            "                                                   tweet                                              tweet label\n",
            "31311             @drm821 æ˜æ—¥ã®æœ¬ç•ªã€ã©ã†ãªã£ã¦ã„ã‚‹ã‹ã€ãƒ„ã‚¤ãƒ¼ãƒˆã«ã”æœŸå¾…ãã ã•ã„â€¦ï¼ï¼                     æ˜æ—¥ã®æœ¬ç•ªã€ã©ã†ãªã£ã¦ã„ã‚‹ã‹ã€ãƒ„ã‚¤ãƒ¼ãƒˆã«ã”æœŸå¾…ãã ã•ã„â€¦ï¼ï¼    ja\n",
            "31312      ã‹ãªã‚Šé›¨é™ã£ã¦ã‚‹ã‘ã©æ™´ã‚Œã‚‹ã®ã‹ã—ã‚‰ãƒ»ãƒ»ãƒ»ä»Šæ—¥ã¯å‡ºã‹ã‘ãªã„ã‹ã‚‰ã©ã£ã¡ã§ã‚‚ã„ã„ã‘ã©ã¡ã‚‡ã£ã¨å¯’ã„      ã‹ãªã‚Šé›¨é™ã£ã¦ã‚‹ã‘ã©æ™´ã‚Œã‚‹ã®ã‹ã—ã‚‰ãƒ»ãƒ»ãƒ»ä»Šæ—¥ã¯å‡ºã‹ã‘ãªã„ã‹ã‚‰ã©ã£ã¡ã§ã‚‚ã„ã„ã‘ã©ã¡ã‚‡ã£ã¨å¯’ã„    ja\n",
            "31313                              ã‚¬ãƒ³ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°æ­´ã¯ãã‚ãã‚10å¹´ã«ãªã‚‹                                ã‚¬ãƒ³ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°æ­´ã¯ãã‚ãã‚å¹´ã«ãªã‚‹    ja\n",
            "31314  2011 FIFAå¥³å­ãƒ¯ãƒ¼ãƒ«ãƒ‰ã‚«ãƒƒãƒ—ã€€ãªã§ã—ã“ã‚¸ãƒ£ãƒ‘ãƒ³ä¸–ç•Œä¸€ ã™ã½ãƒ¬ãƒƒãƒˆã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³-Mic...   fifaå¥³å­ãƒ¯ãƒ¼ãƒ«ãƒ‰ã‚«ãƒƒãƒ—ã€€ãªã§ã—ã“ã‚¸ãƒ£ãƒ‘ãƒ³ä¸–ç•Œä¸€ ã™ã½ãƒ¬ãƒƒãƒˆã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³microsof...    ja\n",
            "31315                                @s19_c88 ã¤ã£ã¡ã‚ƒã‚“ãŠã¯ã‚ˆãƒ¼ã€‚                                         ã¤ã£ã¡ã‚ƒã‚“ãŠã¯ã‚ˆãƒ¼ã€‚    ja\n",
            "---\n",
            "                                                   tweet                                              tweet    label\n",
            "41732  http://t.co/Ym4v14YvtE #Description kara-komik...    karakomikku yakinbyotou ni furuedisyonn opez...  ja_LATN\n",
            "---\n",
            "                                                   tweet                                              tweet label\n",
            "41733  @menarafmbali CemonkWyapeksa dinuskam slm buat...   cemonkwyapeksa dinuskam slm buat yogaalc jube...    jv\n",
            "41734        lek kadung gak mood langsung wegah lapo2 :3           lek kadung gak mood langsung wegah lapo     jv\n",
            "41735  @belgiis1 koe kui lo mbah seng tuwek.an -__- e...    koe kui lo mbah seng tuwekan  eling umur nggih     jv\n",
            "41736  makane maenke ki daendels haha RT @p_bayuprada...  makane maenke ki daendels haha rt  congratulat...    jv\n",
            "41737                    @akhyarnst rokok trossss hahaha                               rokok trossss hahaha    jv\n",
            "---\n",
            "                                                   tweet                                              tweet label\n",
            "41743  á‰á¶áŸ†ááŸ’á“á¶áŸ†á•áŸ’áá¶áŸáŸá¶á™ááŸ’á›á¶áŸ†á–áŸá€á¡á¾á„á‚áŸá‰á›áŸ‚á„á…á„áŸ‹á…á„áŸ‹á€áŸ’ášáŸ„á€á á¾...    á‰á¶áŸ†ááŸ’á“á¶áŸ†á•áŸ’áá¶áŸáŸá¶á™ááŸ’á›á¶áŸ†á–áŸá€á¡á¾á„á‚áŸá‰á›áŸ‚á„á…á„áŸ‹á…á„áŸ‹á€áŸ’ášáŸ„á€á á¾á™    km\n",
            "41744  áŸáŸ’á–á¶á“á¢á¶á€á¶áŸáŸáŸ’á‘á¹á„á˜á¶á“á‡áŸá™á…á¶á”áŸ‹áŠáŸ†áá¾ášá€á¶ášá–á¸ááŸ’á„áŸƒá–áŸ’ášá áŸáŸ’á”...  áŸáŸ’á–á¶á“á¢á¶á€á¶áŸáŸáŸ’á‘á¹á„á˜á¶á“á‡áŸá™á…á¶á”áŸ‹áŠáŸ†áá¾ášá€á¶ášá–á¸ááŸ’á„áŸƒá–áŸ’ášá áŸáŸ’á”...    km\n",
            "---\n",
            "                                                   tweet                                              tweet label\n",
            "41745                   ìŸˆê¸” ìŸˆê¸” ìŸˆê¸” ìŸˆê¸” ìŸˆê¸” ìŸˆê¸” ìŸˆê¸” ìŸˆê¸” ìŸˆê¸” ìŸˆê¸” ìŸˆê¸”                   ìŸˆê¸” ìŸˆê¸” ìŸˆê¸” ìŸˆê¸” ìŸˆê¸” ìŸˆê¸” ìŸˆê¸” ìŸˆê¸” ìŸˆê¸” ìŸˆê¸” ìŸˆê¸”    ko\n",
            "41746                                 @sweetieYH ê·¸ë‹ˆê¹Œã…‹ã…‹ã…‹ã…‹                                            ê·¸ë‹ˆê¹Œã…‹ã…‹ã…‹ã…‹    ko\n",
            "41747  ã… ã… ã… ã… ã… ã… ã… ã… ã… ã… ã… ã… ã… ã… ã… ã… ã… ã… ã… ã… ã… ã… ã… ã… ã… ã… ã… ã… ã… ã… ã… ã… ã… ã… ã… ã… ã… ã… ã… ã… ã… ã… ã… ã… ã… ã… ...  ã… ã… ã… ã… ã… ã… ã… ã… ã… ã… ã… ã… ã… ã… ã… ã… ã… ã… ã… ã… ã… ã… ã… ã… ã… ã… ã… ã… ã… ã… ã… ã… ã… ã… ã… ã… ã… ã… ã… ã… ã… ã… ã… ã… ã… ã… ...    ko\n",
            "41748                                     @hscha87 ëª»ë‚œì•„..                                                ëª»ë‚œì•„    ko\n",
            "41749  ì–´ì œë‘ ë˜‘ê°™ì€ ìŒì•… ë˜‘ê°™ì€ ë¶€ë¶„ì—ì„œ ì»´ì´ ë©ˆì¶”ê¸¸ë˜ í˜¹ì‹œë‚˜ í•´ì„œ ì‹œí—˜í•´ë´¤ë‹¤ ì¥ë¯¸ì˜ ê¸°...  ì–´ì œë‘ ë˜‘ê°™ì€ ìŒì•… ë˜‘ê°™ì€ ë¶€ë¶„ì—ì„œ ì»´ì´ ë©ˆì¶”ê¸¸ë˜ í˜¹ì‹œë‚˜ í•´ì„œ ì‹œí—˜í•´ë´¤ë‹¤ ì¥ë¯¸ì˜ ê¸°...    ko\n",
            "---\n",
            "                      tweet     tweet    label\n",
            "42203  @SL_kyuraw gomawoo:)   gomawoo  ko_LATN\n",
            "---\n",
            "Empty DataFrame\n",
            "Columns: [tweet, tweet, label]\n",
            "Index: []\n",
            "---\n",
            "Empty DataFrame\n",
            "Columns: [tweet, tweet, label]\n",
            "Index: []\n",
            "---\n",
            "Empty DataFrame\n",
            "Columns: [tweet, tweet, label]\n",
            "Index: []\n",
            "---\n",
            "Empty DataFrame\n",
            "Columns: [tweet, tweet, label]\n",
            "Index: []\n",
            "---\n",
            "Empty DataFrame\n",
            "Columns: [tweet, tweet, label]\n",
            "Index: []\n",
            "---\n",
            "                                                   tweet                                              tweet label\n",
            "42204  Sed fugit interea,fugit irreparabile tempus, s...  sed fugit intereafugit irreparabile tempus sin...    ms\n",
            "42205  @iloveshf Aku tadi baru nampak dia! Senyum je ...   aku tadi baru nampak dia senyum je aku mampu ...    ms\n",
            "42206  @nazirulhaziqs: @ItsMymie_ haha. hzq rendah je...    haha hzq rendah je okay mcm budak darjah  ha...    ms\n",
            "42207                          Hati berasa dupan ye haha                          hati berasa dupan ye haha    ms\n",
            "42208  So tak boleh la beli jongkong emas simpan kat ...  so tak boleh la beli jongkong emas simpan kat ...    ms\n",
            "---\n",
            "                                                   tweet                                              tweet label\n",
            "42328  Foeballuh! â€œ@Spitstwit: Gamecolumn: Het is maa...  foeballuh â€œ gamecolumn het is maar een spellet...    nl\n",
            "42329                        Proefwerken gimgen best okÃ©                        proefwerken gimgen best okÃ©    nl\n",
            "42330  @ANWBverkeer dus via de A15 - A4 ?  Wellicht d...   dus via de a  a   wellicht dit te vermelden t...    nl\n",
            "42331  La Mer kiest voor Beautypartner als leverancie...  la mer kiest voor beautypartner als leverancie...    nl\n",
            "42332  Willem Drees had dat al snel door dat de socia...  willem drees had dat al snel door dat de socia...    nl\n",
            "---\n",
            "                                                   tweet                                              tweet label\n",
            "42510  Nytt pris: E85: 8,88 B95: 14,25 Diesel: 14,02 ...                        nytt pris e  b  diesel         no\n",
            "42511  AUF vil la deler av kafÃ©bygget pÃ¥ UtÃ¸ya bestÃ¥ ...  auf vil la deler av kafÃ©bygget pÃ¥ utÃ¸ya bestÃ¥ ...    no\n",
            "42512  @Harryisthecraic kjÃ¦resten til sÃ¸skenbarnet mi...   kjÃ¦resten til sÃ¸skenbarnet mitt er her og fra...    no\n",
            "42513  @OpkvitneEaters Fifas disciplinary code er skr...   fifas disciplinary code er skrevet slik at ma...    no\n",
            "42514  Neymar av banen med Norges folkesykdom. Vondt ...  neymar av banen med norges folkesykdom vondt i...    no\n",
            "---\n",
            "                                                   tweet                                              tweet label\n",
            "42521  Edward III nie mÃ³gÅ‚ zostaÄ‡... - http://t.co/ii...                       edward iii nie mÃ³gÅ‚ zostaÄ‡      pl\n",
            "42522  @perfctcalum wÅ‚aÅ›nie sie skaplam ze ty mialam ...   wÅ‚aÅ›nie sie skaplam ze ty mialam z tego ikonk...    pl\n",
            "42523             @mailencanossini: kolor frrrreza #lulu                                    kolor frrrreza     pl\n",
            "42524                    @zarrydiary ty mi nie odpisaÅ‚as                                ty mi nie odpisaÅ‚as    pl\n",
            "42525  @awhmyleigh Ale to przecieÅ¼ fair... Poza tym t...   ale to przecieÅ¼ fair poza tym to tylko na chw...    pl\n",
            "---\n",
            "                                                   tweet                                              tweet label\n",
            "42616                                     meio estranho!                                      meio estranho    pt\n",
            "42617  NÃ£o se gostam?  Vai um pra cada lado e pronto ...  nÃ£o se gostam  vai um pra cada lado e pronto p...    pt\n",
            "42618  Eu adoro ir Ã s compras. Olha sÃ³ o que eu compr...  eu adoro ir Ã s compras olha sÃ³ o que eu compre...    pt\n",
            "42619  @gruviquantica estas muito sofisticada esses Ãº...   estas muito sofisticada esses Ãºltimos dias amiga    pt\n",
            "42620                                    Boa noite â™¥ â˜º '                                       boa noite       pt\n",
            "---\n",
            "                                                   tweet                                              tweet label\n",
            "45494                                           Revoltei                                           revoltei    ro\n",
            "45495  #Horizon2020 este cel mai amplu program de cer...   este cel mai amplu program de cercetare al ue...    ro\n",
            "45496  @ElenaRogoz Mda da! Acum o saptamana 0.0 sper ...   mda da acum o saptamana  sper ca macar incerc...    ro\n",
            "45497  ITI PERMITI acum sa-ti faci publicitate! 100 d...  iti permiti acum sati faci publicitate  de eur...    ro\n",
            "45498  Tracy Morgan, victimÄƒ a unui accident rutier c...  tracy morgan victimÄƒ a unui accident rutier ca...    ro\n",
            "---\n",
            "                                                   tweet                                              tweet label\n",
            "45506                    @egosh_69 Ğ² 6 ÑƒÑ‚Ñ€Ğ°?ĞµÑÑ‚ÑŒ?Ğ°Ñ…Ğ°Ñ…Ğ°Ñ…Ğ°                                 Ğ²  ÑƒÑ‚Ñ€Ğ°ĞµÑÑ‚ÑŒĞ°Ñ…Ğ°Ñ…Ğ°Ñ…Ğ°    ru\n",
            "45507  ĞšĞ¸Ğ½Ğ¾Ñ„Ğ¸Ğ»ÑŒĞ¼ ÑĞ¾Ğ±Ñ€Ğ°Ğ» Ğ·Ğ° Ğ²Ñ€ĞµĞ¼Ñ Ğ¿Ñ€Ğ¾ĞºĞ°Ñ‚Ğ° 230 984 145 ...  ĞºĞ¸Ğ½Ğ¾Ñ„Ğ¸Ğ»ÑŒĞ¼ ÑĞ¾Ğ±Ñ€Ğ°Ğ» Ğ·Ğ° Ğ²Ñ€ĞµĞ¼Ñ Ğ¿Ñ€Ğ¾ĞºĞ°Ñ‚Ğ°    Ñ€ÑƒĞ± Ğ½Ğ° Ğ½Ğµ...    ru\n",
            "45508  ĞŸÑ€Ğ¸Ñ‚Ñ‡Ğ° Ğ¾ Ñ€Ğ°Ğ·Ğ²Ğ¾Ğ´Ğµ | Ğ¡Ğ²Ğ°Ğ´ĞµĞ±Ğ½Ñ‹Ğ¹ ĞºĞ¾ĞºÑ‚ĞµĞ¹Ğ»ÑŒ http://t...             Ğ¿Ñ€Ğ¸Ñ‚Ñ‡Ğ° Ğ¾ Ñ€Ğ°Ğ·Ğ²Ğ¾Ğ´Ğµ | ÑĞ²Ğ°Ğ´ĞµĞ±Ğ½Ñ‹Ğ¹ ĞºĞ¾ĞºÑ‚ĞµĞ¹Ğ»ÑŒ     ru\n",
            "45509     ĞŸÑ€Ğ¾ĞµĞºÑ‚Ñ‹ Ğ´Ğ¾Ğ¼Ğ¾Ğ² Ğ¸Ğ· Ğ±Ñ€ĞµĞ²Ğ½Ğ° http://t.co/nKtLxsiBhD                           Ğ¿Ñ€Ğ¾ĞµĞºÑ‚Ñ‹ Ğ´Ğ¾Ğ¼Ğ¾Ğ² Ğ¸Ğ· Ğ±Ñ€ĞµĞ²Ğ½Ğ°     ru\n",
            "45510         8-Ñ ÑĞµÑ€Ğ¸Ñ 03.07.2014 ÑĞ¼Ğ¾Ñ‚Ñ€ĞµÑ‚ÑŒ Ğ¾Ğ½Ğ»Ğ°Ğ¹Ğ½ - 2x2                        Ñ ÑĞµÑ€Ğ¸Ñ  ÑĞ¼Ğ¾Ñ‚Ñ€ĞµÑ‚ÑŒ Ğ¾Ğ½Ğ»Ğ°Ğ¹Ğ½  x    ru\n",
            "---\n",
            "Empty DataFrame\n",
            "Columns: [tweet, tweet, label]\n",
            "Index: []\n",
            "---\n",
            "                                                   tweet                                              tweet label\n",
            "46496            a boli uvo svajcarsku, puni su k'o brod              a boli uvo svajcarsku puni su ko brod    sr\n",
            "46497                            Prekini da mi se drkaÅ¡.                             prekini da mi se drkaÅ¡    sr\n",
            "46498  Nosim samo Nike, imam dijamantska pluca  Äek s...  nosim samo nike imam dijamantska pluca  Äek sa...    sr\n",
            "46499         ZAÅ TO JE ENDRU SKOT GEJ, ZAÅ TOOOOOOOOOOOOO          zaÅ¡to je endru skot gej zaÅ¡tooooooooooooo    sr\n",
            "46500  ÄOKOVIÄ†: TeÅ¡ko bilo posle Äetvrtog seta | Srbi...  Ä‘okoviÄ‡ teÅ¡ko bilo posle Äetvrtog seta | srbij...    sr\n",
            "---\n",
            "                                                   tweet                                              tweet label\n",
            "46528  @Wilbacher PÃ¥ riktigt alltsÃ¥. Du fÃ¥r 10% av in...         pÃ¥ riktigt alltsÃ¥ du fÃ¥r  av intÃ¤kterna ok    sv\n",
            "46529  Mora satsar fÃ¶r att vara med i kampen om SHL-p...  mora satsar fÃ¶r att vara med i kampen om shlpl...    sv\n",
            "46530  VÃ¥rt glamourÃ¶sa backstageomrÃ¥de. LÃ¤ngst upp ti...  vÃ¥rt glamourÃ¶sa backstageomrÃ¥de lÃ¤ngst upp til...    sv\n",
            "46531  @rudbergamanda nice! Vill fan ocksÃ¥ tillbaka r...    nice vill fan ocksÃ¥ tillbaka redan nu i sommar     sv\n",
            "46532  @Krakel_ @kringelkrokar  Ta tilllbaka Kentas l...            ta tilllbaka kentas lÃ¥t frÃ¥n rasisterna    sv\n",
            "---\n",
            "                                                   tweet                                              tweet label\n",
            "46582  LMFAOO RT \"@Limo_alan: \"@Emahnue: Ziko wapi iz...  lmfaoo rt limoalan emahnue ziko wapi izo scree...    sw\n",
            "46583  HATIMAYE MWISHO WA DUNIA UMEKARIBIA..!! FREEMA...  hatimaye mwisho wa dunia umekaribia freemason ...    sw\n",
            "46584                         @stevengitz nilipoteza cmu                                     nilipoteza cmu    sw\n",
            "46585  Liverpool yamsajili Markovic kwa Â£20m kuziba p...  liverpool yamsajili markovic kwa Â£m kuziba pengo     sw\n",
            "46586  KUELEKEA UCHAGUZI 2015:: VIJANA WAAMUA KUTANGA...  kuelekea uchaguzi  vijana waamua kutangaza nia...    sw\n",
            "---\n",
            "                                                   tweet                                              tweet label\n",
            "46588  à®šà®¾à®°à¯.à®‰à®™à¯à®• à®ªà®´à¯ˆà®¯ à®¨à®¾à®µà®²à¯ˆ à®à®²à¯à®²à®¾à®®à¯ à®•à®¿à®²à¯‹ 50 à®°à¯‚à®ªà®¾ à®•à¯à®•à¯...  à®šà®¾à®°à¯à®‰à®™à¯à®• à®ªà®´à¯ˆà®¯ à®¨à®¾à®µà®²à¯ˆ à®à®²à¯à®²à®¾à®®à¯ à®•à®¿à®²à¯‹  à®°à¯‚à®ªà®¾ à®•à¯à®•à¯ à®µà®¾...    ta\n",
            "46589                      @silvakaskas à®¤à®¿à®°à¯à®Ÿà®¾ à®¨à®¾à®©à¯ à®°à¯†à®Ÿà®¿                                   à®¤à®¿à®°à¯à®Ÿà®¾ à®¨à®¾à®©à¯ à®°à¯†à®Ÿà®¿    ta\n",
            "46590  MH17 :à®…à®¤à®¿à®°à¯à®·à¯à®Ÿà®µà®šà®®à®¾à®• à®¤à®ªà¯à®ªà®¿à®¯ à®ªà®¿à®°à®¿à®Ÿà¯à®Ÿà®©à¯ à®¤à®®à¯à®ªà®¤à®¿ ht...          mh à®…à®¤à®¿à®°à¯à®·à¯à®Ÿà®µà®šà®®à®¾à®• à®¤à®ªà¯à®ªà®¿à®¯ à®ªà®¿à®°à®¿à®Ÿà¯à®Ÿà®©à¯ à®¤à®®à¯à®ªà®¤à®¿     ta\n",
            "46591  à®ªà®¾à®°à¯à®µà¯ˆà®¯à®±à¯à®± à®•à¯à®´à®¨à¯à®¤à¯ˆà®•à®³à¯ˆ à®…à®Ÿà®¿à®¤à¯à®¤à¯à®¤à¯ à®¤à¯à®©à¯à®ªà¯à®±à¯à®¤à¯à®¤à®¿à®¯ ...  à®ªà®¾à®°à¯à®µà¯ˆà®¯à®±à¯à®± à®•à¯à®´à®¨à¯à®¤à¯ˆà®•à®³à¯ˆ à®…à®Ÿà®¿à®¤à¯à®¤à¯à®¤à¯ à®¤à¯à®©à¯à®ªà¯à®±à¯à®¤à¯à®¤à®¿à®¯ ...    ta\n",
            "46592                         à®…à®à¯à®šà®¾à®©à¯ à®ªà®¾à®Ÿà®²à¯à®•à®³à¯ à®•à®¿à®Ÿà¯ˆà®šà¯à®šà®¤à®¾                         à®…à®à¯à®šà®¾à®©à¯ à®ªà®¾à®Ÿà®²à¯à®•à®³à¯ à®•à®¿à®Ÿà¯ˆà®šà¯à®šà®¤à®¾    ta\n",
            "---\n",
            "                          tweet            tweet    label\n",
            "46597  @bunbaby1 Vanakkam fakeu   vanakkam fakeu  ta_LATN\n",
            "---\n",
            "                                                   tweet                                              tweet label\n",
            "46598      @BTSJK_97BOT @jungkook_fxxk à¸à¸¶à¹ˆà¸‡à¹€à¸¥à¸´à¸à¹€à¸£à¸µà¸¢à¸™ -.-                                     à¸à¸¶à¹ˆà¸‡à¹€à¸¥à¸´à¸à¹€à¸£à¸µà¸¢à¸™     th\n",
            "46599             à¸™à¹‰à¸­à¸‡à¸•à¹‰à¸§à¸™à¸à¸±à¸šà¹à¸ˆà¹Šà¸„à¸ªà¸±à¸™à¹à¸¥à¸°à¹€à¸ˆà¸šà¸µà¸®à¸²à¸¡à¸²à¸ à¹„à¸­à¸ªà¸²à¸”à¸”à¸”             à¸™à¹‰à¸­à¸‡à¸•à¹‰à¸§à¸™à¸à¸±à¸šà¹à¸ˆà¹Šà¸„à¸ªà¸±à¸™à¹à¸¥à¸°à¹€à¸ˆà¸šà¸µà¸®à¸²à¸¡à¸²à¸ à¹„à¸­à¸ªà¸²à¸”à¸”à¸”    th\n",
            "46600  à¸—à¸³à¹„à¸¡à¸à¸´à¸™à¸à¸¥à¸¹à¸•à¹‰à¸²à¹à¸¥à¹‰à¸§à¹„à¸¡à¹ˆà¹€à¸«à¸™à¸œà¸¥à¸‹à¸±à¸à¸—à¸µ à¸§à¸±à¸™à¸™à¸µà¹ˆà¸¡à¸µà¸„à¸³à¸•à¸­à¸š h...      à¸—à¸³à¹„à¸¡à¸à¸´à¸™à¸à¸¥à¸¹à¸•à¹‰à¸²à¹à¸¥à¹‰à¸§à¹„à¸¡à¹ˆà¹€à¸«à¸™à¸œà¸¥à¸‹à¸±à¸à¸—à¸µ à¸§à¸±à¸™à¸™à¸µà¹ˆà¸¡à¸µà¸„à¸³à¸•à¸­à¸š     th\n",
            "46601  à¸¥à¸¹à¸à¹€à¸«à¸¡à¹‡à¸™à¸™à¸µà¹ˆà¸¡à¸±à¸™à¹€à¸«à¸¡à¹‡à¸™à¸ªà¸¡à¸Šà¸·à¹ˆà¸­à¸ˆà¸£à¸´à¸‡à¹† à¸•à¸­à¸™à¸™à¸µà¹‰à¸ªà¸±à¸šà¸ªà¸™à¸§à¹ˆà¸²à¸...  à¸¥à¸¹à¸à¹€à¸«à¸¡à¹‡à¸™à¸™à¸µà¹ˆà¸¡à¸±à¸™à¹€à¸«à¸¡à¹‡à¸™à¸ªà¸¡à¸Šà¸·à¹ˆà¸­à¸ˆà¸£à¸´à¸‡à¹† à¸•à¸­à¸™à¸™à¸µà¹‰à¸ªà¸±à¸šà¸ªà¸™à¸§à¹ˆà¸²à¸...    th\n",
            "46602                                    à¸­à¸¢à¸²à¸à¸«à¸¥à¸±à¸šà¸ªà¸±à¸10à¸›à¸µ                                      à¸­à¸¢à¸²à¸à¸«à¸¥à¸±à¸šà¸ªà¸±à¸à¸›à¸µ    th\n",
            "---\n",
            "                                                   tweet                                              tweet label\n",
            "47060  At least yung mukha ko d malala tulad ni Jayso...  at least yung mukha ko d malala tulad ni jayso...    tl\n",
            "47061           Yung mga nag uunfollow mga pa famous ./.              yung mga nag uunfollow mga pa famous     tl\n",
            "47062  @ALTHEADELATORRE Ayy. Di naman ganon yung akin...                      ayy di naman ganon yung akin     tl\n",
            "47063                  Yesss! Galing selos ako kuya! ./.                       yesss galing selos ako kuya     tl\n",
            "47064  @avegaille ah.. kala ko fan ka din ng f1. ğŸ˜Š pa...   ah kala ko fan ka din ng f  para akong one of...    tl\n",
            "---\n",
            "                                                   tweet                                              tweet label\n",
            "47381  I'm at Avrupa BirliÄŸi BakanlÄ±ÄŸÄ± w/ 6 others ht...          im at avrupa birliÄŸi bakanlÄ±ÄŸÄ± w  others     tr\n",
            "47382                    @ALKOLKAFAYAPAR ben uyumadÄ±m da                                    ben uyumadÄ±m da    tr\n",
            "47383                    cigjofte seven kizlar selam :dd                     cigjofte seven kizlar selam dd    tr\n",
            "47384  DÃ¼nya mazlumlarÄ±nÄ±n umudu. Rabbim yolunu aÃ§Ä±k ...  dÃ¼nya mazlumlarÄ±nÄ±n umudu rabbim yolunu aÃ§Ä±k e...    tr\n",
            "47385  millet aÅŸk derdine dÃ¼ÅŸmÃ¼ÅŸ biz burda iftar saat...  millet aÅŸk derdine dÃ¼ÅŸmÃ¼ÅŸ biz burda iftar saat...    tr\n",
            "---\n",
            "                                                   tweet                                              tweet label\n",
            "48050  Ğ’ Ğ£Ğ¶Ğ³Ğ¾Ñ€Ğ¾Ğ´Ñ– ÑĞ²ÑÑ‰ĞµĞ½Ğ¸Ğº Ğ·Ğ°Ñ‚Ñ€Ğ¸Ğ¼Ğ°Ğ² Ğ¿Ñ–Ğ´Ğ¾Ğ·Ñ€Ñ–Ğ»Ğ¾Ğ³Ğ¾ Â«Ñ„Ğ¾Ñ‚Ğ¾...  Ğ² ÑƒĞ¶Ğ³Ğ¾Ñ€Ğ¾Ğ´Ñ– ÑĞ²ÑÑ‰ĞµĞ½Ğ¸Ğº Ğ·Ğ°Ñ‚Ñ€Ğ¸Ğ¼Ğ°Ğ² Ğ¿Ñ–Ğ´Ğ¾Ğ·Ñ€Ñ–Ğ»Ğ¾Ğ³Ğ¾ Â«Ñ„Ğ¾Ñ‚Ğ¾...    uk\n",
            "48051  #Ñ„Ğ¸Ñ‚Ğ½ĞµÑ #ÑĞ¿Ğ¾Ñ€Ñ‚ #Ğ°ĞºÑ†Ğ¸Ğ¸ #fitness #lviv #lvov #Ğ›ÑŒ...  Ñ„Ğ¸Ñ‚Ğ½ĞµÑ ÑĞ¿Ğ¾Ñ€Ñ‚ Ğ°ĞºÑ†Ğ¸Ğ¸    Ğ»ÑŒĞ²Ğ¾Ğ² zumba Ğ½Ğ° Ğ²ÑƒĞ» Ğ½Ğ°ÑƒĞºĞ¾...    uk\n",
            "48052  @UKRINFORM @ukrpravda_news Ğ¥Ğ²Ğ°Ñ‚Ğ¸Ñ‚ÑŒ! ĞœĞ¸ Ğ·Ğ½Ğ°Ñ”Ğ¼Ğ¾ ...    Ñ…Ğ²Ğ°Ñ‚Ğ¸Ñ‚ÑŒ Ğ¼Ğ¸ Ğ·Ğ½Ğ°Ñ”Ğ¼Ğ¾ Ñ‰Ğ¾ Ğ²Ğ¾Ğ½Ğ¸ ÑÑ‚ÑƒÑ€Ğ±Ğ¾Ğ²Ğ°Ğ½Ñ– Ğ²Ğ¶Ğµ Ğ¿Ñ–Ğ²...    uk\n",
            "48053  Ğ¯Ñ†ĞµĞ½ÑĞº Ğ¾Ñ‡Ñ–ĞºÑƒÑ”, Ñ‰Ğ¾ Ğ·Ğ° 10 Ñ€Ğ¾ĞºÑ–Ğ² Ğ£ĞºÑ€Ğ°Ñ—Ğ½Ğ° Ğ±ÑƒĞ´Ğµ Ğ¿Ğ¾Ğ²...  ÑÑ†ĞµĞ½ÑĞº Ğ¾Ñ‡Ñ–ĞºÑƒÑ” Ñ‰Ğ¾ Ğ·Ğ°  Ñ€Ğ¾ĞºÑ–Ğ² ÑƒĞºÑ€Ğ°Ñ—Ğ½Ğ° Ğ±ÑƒĞ´Ğµ Ğ¿Ğ¾Ğ²Ğ½Ñ–Ñ...    uk\n",
            "48054  Ğ’Ğ¾Ğ»Ğ¾Ğ½Ñ‚ĞµÑ€Ğ¸ Ğ¿ĞµÑ€ĞµĞ´Ğ°Ğ»Ğ¸ Ğ½Ğ° Ğ”Ğ¾Ğ½Ğ±Ğ°Ñ Ğ±ï¿½... http://t.co...                   Ğ²Ğ¾Ğ»Ğ¾Ğ½Ñ‚ĞµÑ€Ğ¸ Ğ¿ĞµÑ€ĞµĞ´Ğ°Ğ»Ğ¸ Ğ½Ğ° Ğ´Ğ¾Ğ½Ğ±Ğ°Ñ Ğ±ï¿½     uk\n",
            "---\n",
            "                                                   tweet                  tweet label\n",
            "48066  â€œ@NkealHarry15: Rasta E-Mann ğŸ˜‚ğŸ˜‚ğŸ˜‚ @EmannHamm_TY...       â€œ rasta emann      und\n",
            "48067                                 @MonaKazok  ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚                          und\n",
            "48068                             #aliadosestasdemassss!                          und\n",
            "48069                                  Padahal wes onlen      padahal wes onlen   und\n",
            "48070                 #ì¬íš¨íš¨ì§„í–‰ì‡¼ #ì¬íš¨ì§„í–‰ì‡¼ #ì•ˆì¬íš¨â™¡ë¬¸íš¨ì§„ @blockbhyo  ì¬íš¨íš¨ì§„í–‰ì‡¼ ì¬íš¨ì§„í–‰ì‡¼ ì•ˆì¬íš¨â™¡ë¬¸íš¨ì§„    und\n",
            "---\n",
            "                                                   tweet                                              tweet label\n",
            "52603  Ø¨Ø±Ø·Ø§Ù†ÛŒÛ: Ø³ÛŒØ§Û ÙØ§Ù… Ø¨Ú†Û’ Ø²ÛŒØ§Ø¯Û ÙÚ©Ø±Ù…Ù†Ø¯ http://t.co...                 Ø¨Ø±Ø·Ø§Ù†ÛŒÛ Ø³ÛŒØ§Û ÙØ§Ù… Ø¨Ú†Û’ Ø²ÛŒØ§Ø¯Û ÙÚ©Ø±Ù…Ù†Ø¯     ur\n",
            "52604  Ú†Ú¾ÙÙ† Ù†Û Ø¬Ø§Ø¦Û’ ØªØ±Ø§ ØªØ¨Ø³Ù‘Ù…Ù Ù„Ø¨ ØŒ   Ù…ÛŒØ±Û’ Ø¯Ø±Ø¯ Ùˆ Ø§Ù„Ù… ...  Ú†Ú¾ÙÙ† Ù†Û Ø¬Ø§Ø¦Û’ ØªØ±Ø§ ØªØ¨Ø³Ù‘Ù…Ù Ù„Ø¨ ØŒ   Ù…ÛŒØ±Û’ Ø¯Ø±Ø¯ Ùˆ Ø§Ù„Ù… ...    ur\n",
            "52605  @phanerozoic11 @dufferistan Ú©Ø³ Ú©Û’ Ø³Ø§ØªÚ¾ Ú©ÛŒØ§ ÛÙˆØ±...                            Ú©Ø³ Ú©Û’ Ø³Ø§ØªÚ¾ Ú©ÛŒØ§ ÛÙˆØ±ÛŒØ§ØŸ      ur\n",
            "52606  Ø¬Ù…Ø§Ø¹Øª Ø§Ø­Ù…Ø¯ÛŒÛ Ú©Û’ Ø¨Ø§Ø±Û’ Ø­Ù‚Ø§Ø¦Ù‚ Ø§ÙˆØ± Ù¾Ø§Ú©Ø³ØªØ§Ù† Ú©ÛŒ Ù…ÙˆØ¬Ùˆ...  Ø¬Ù…Ø§Ø¹Øª Ø§Ø­Ù…Ø¯ÛŒÛ Ú©Û’ Ø¨Ø§Ø±Û’ Ø­Ù‚Ø§Ø¦Ù‚ Ø§ÙˆØ± Ù¾Ø§Ú©Ø³ØªØ§Ù† Ú©ÛŒ Ù…ÙˆØ¬Ùˆ...    ur\n",
            "52607  Ú©Ú†Ú¾ Ù„ÙˆÚ¯ Ù†Ù…Ø§Ø² Ù¾Ú‘Ú¾ØªÛ’ ÛÛŒÚº ØŒ Ø±ÙˆØ²Û Ø±Ú©Ú¾ØªÛ’ ÛÛŒÚº ÛØ± ÙˆÛ ...  Ú©Ú†Ú¾ Ù„ÙˆÚ¯ Ù†Ù…Ø§Ø² Ù¾Ú‘Ú¾ØªÛ’ ÛÛŒÚº ØŒ Ø±ÙˆØ²Û Ø±Ú©Ú¾ØªÛ’ ÛÛŒÚº ÛØ± ÙˆÛ ...    ur\n",
            "---\n",
            "                                                   tweet                                              tweet    label\n",
            "52610  Dawar-e-Hasaar Ne Ehy Keh Ky Mujhy Bakash Dia ...  dawarehasaar ne ehy keh ky mujhy bakash dia kh...  ur_LATN\n",
            "52611  @preeti_luvkcnwk wah wah sukriya aapka...iss s...   wah wah sukriya aapkaiss shandar swagat ke li...  ur_LATN\n",
            "52612  @Wiseguy70 @VneedChange @waqas_azeem_ch @AnamK...                            aik jadu ki jhapi do na  ur_LATN\n",
            "52613  Qur'an Mein Tajdeed Ka Tariqa http://t.co/z19N...             quran mein tajdeed ka tariqa            ur_LATN\n",
            "52614  @Nice_DuLHaN: Nahi Hum MOhtaaj Kisi Ke Ek Tere...   nahi hum mohtaaj kisi ke ek terey siwa yaa al...  ur_LATN\n",
            "---\n",
            "                                                   tweet                                              tweet label\n",
            "52622  MÃ™A HÃˆ 2014 MÃ¹a hÃ¨ Ä‘áº¿n lÃ  dá»‹p Ä‘á»ƒ gia Ä‘Ã¬nh báº¡n ...  mÃ¹a hÃ¨  mÃ¹a hÃ¨ Ä‘áº¿n lÃ  dá»‹p Ä‘á»ƒ gia Ä‘Ã¬nh báº¡n tung...    vi\n",
            "52623  TÃ´i Ä‘Ã£ thÃ­ch video http://t.co/dm62mcF9EU [Alo...  tÃ´i Ä‘Ã£ thÃ­ch video  alozovn gháº¿ Ä‘Æ°a Ä‘a nÄƒng sl...    vi\n",
            "52624  LÃ¹ hÃ¡n Ã  =)))))))))))))) lÃºc uá»‘ng nc' Ä‘áº¯ng thÃ¬...  lÃ¹ hÃ¡n Ã   lÃºc uá»‘ng nc Ä‘áº¯ng thÃ¬ máº·t nhÄƒn cÃ²n  n...    vi\n",
            "52625  Khi má»™t ngÆ°á»i quyáº¿t Ä‘á»‹nh IM Láº¶NG...  . KhÃ´ng p...  khi má»™t ngÆ°á»i quyáº¿t Ä‘á»‹nh im láº·ng   khÃ´ng pháº£i ...    vi\n",
            "52626                    ngÃ y Ä‘áº¹p zá»i vÃ  ráº¥t buá»“n ngá»§ :(                      ngÃ y Ä‘áº¹p zá»i vÃ  ráº¥t buá»“n ngá»§     vi\n",
            "---\n",
            "                                                   tweet                                              tweet label\n",
            "52639  @SJLRadio1 @Umhlobo_Wenene @Maxhoseni @NonalaT...      n ndimpha zonke  ifani ingoma ezimnandi na...    xh\n",
            "---\n",
            "Empty DataFrame\n",
            "Columns: [tweet, tweet, label]\n",
            "Index: []\n",
            "---\n",
            "                                                   tweet                                              tweet  label\n",
            "52640                        è¢«è‚†æ„å¹æ§å‡ºæ¥çš„â€œç»å…¸â€ä½œå®¶ï¼Œå¦‚ï¼šå†°å¿ƒï¼ŒçŸ›ç›¾ï¼Œéƒ­æ²«è‹¥ç­‰                        è¢«è‚†æ„å¹æ§å‡ºæ¥çš„â€œç»å…¸â€ä½œå®¶ï¼Œå¦‚ï¼šå†°å¿ƒï¼ŒçŸ›ç›¾ï¼Œéƒ­æ²«è‹¥ç­‰  zh-CN\n",
            "52641      ä¸€ç›´è®©ä½ æµæ³ªçš„æ¡ä»¶å†å¥½ä¹Ÿä¸èƒ½è¦ï¼Œä¸€ç›´è®©ä½ ç¬‘çš„ï¼Œå°±ç®—åƒè‹¦ä¹Ÿå€¼å¾—ã€‚å®å¯ç¬‘ç€ç´¯ï¼Œä¹Ÿä¸è¦å“­ç€äº«å—ã€‚      ä¸€ç›´è®©ä½ æµæ³ªçš„æ¡ä»¶å†å¥½ä¹Ÿä¸èƒ½è¦ï¼Œä¸€ç›´è®©ä½ ç¬‘çš„ï¼Œå°±ç®—åƒè‹¦ä¹Ÿå€¼å¾—ã€‚å®å¯ç¬‘ç€ç´¯ï¼Œä¹Ÿä¸è¦å“­ç€äº«å—ã€‚  zh-CN\n",
            "52642  çƒ­ç‚¹æ–‡ç« ï¼šã€Šã€Šäº¬åŸ81å·ã€‹å´é•‡å®‡ç‰¹è¾‘â€”åœ¨çº¿æ’­æ”¾â€”ä¼˜é…·ç½‘ï¼Œè§†é¢‘é«˜æ¸…åœ¨çº¿è§‚çœ‹ã€‹ http://t...        çƒ­ç‚¹æ–‡ç« ï¼šã€Šã€Šäº¬åŸå·ã€‹å´é•‡å®‡ç‰¹è¾‘â€”åœ¨çº¿æ’­æ”¾â€”ä¼˜é…·ç½‘ï¼Œè§†é¢‘é«˜æ¸…åœ¨çº¿è§‚çœ‹ã€‹  åŸç«™é“¾æ¥ï¼š   zh-CN\n",
            "52643  æˆ‘å–å¾—äº†ä¸€é¡¹æ–°æˆå°±ï¼š`ç®¡ç†å‘˜`.å°è¯•åœ¨iPadç‰ˆTribezæ¸¸æˆä¸­æ‰“è´¥æˆ‘å§ï¼http://t...              æˆ‘å–å¾—äº†ä¸€é¡¹æ–°æˆå°±ï¼šç®¡ç†å‘˜å°è¯•åœ¨ipadç‰ˆtribezæ¸¸æˆä¸­æ‰“è´¥æˆ‘å§ï¼    zh-CN\n",
            "52644  çœŸä½›å®—å¤§é©¬å„åˆ†å ‚ä¸­å…ƒèŠ‚æ³•ä¼šæ´»åŠ¨ï¼Œæ¬¢è¿æŠ¤æŒ !  å†œå†ä¸ƒæœˆçš„ã€ä¸­å…ƒç¯€ã€å³å°†åˆ°æ¥ã€‚å†œå†ä¸ƒæœˆæ˜¯ä½›æ•™...  çœŸä½›å®—å¤§é©¬å„åˆ†å ‚ä¸­å…ƒèŠ‚æ³•ä¼šæ´»åŠ¨ï¼Œæ¬¢è¿æŠ¤æŒ   å†œå†ä¸ƒæœˆçš„ã€ä¸­å…ƒç¯€ã€å³å°†åˆ°æ¥ã€‚å†œå†ä¸ƒæœˆæ˜¯ä½›æ•™çš„...  zh-CN\n",
            "---\n",
            "                                                   tweet                                              tweet  label\n",
            "52665   @EmmaKongms æ‰€ä»¥æˆ‘åœ°è¦å«æœ‹å‹ä¾†é–‹account å…ˆï¼Œç·Šæ€¥æƒ…æ³è¦è­˜è½‰å°ç‡Twitter               æ‰€ä»¥æˆ‘åœ°è¦å«æœ‹å‹ä¾†é–‹account å…ˆï¼Œç·Šæ€¥æƒ…æ³è¦è­˜è½‰å°ç‡twitter  zh-TW\n",
            "52666  ã€ŠéŸ³é€Ÿç¶“ç´€ã€‹æ–¼èƒŒåœ°è£¡æ”¯æ´éŸ³é€Ÿå­ å¼•å°ç©å®¶çš„ â€œéŸ³æ¨‚å¥³ç¥â€ã€Œç¹†æ–¯ã€ç™»å ´ http://t.co...                ã€ŠéŸ³é€Ÿç¶“ç´€ã€‹æ–¼èƒŒåœ°è£¡æ”¯æ´éŸ³é€Ÿå­ å¼•å°ç©å®¶çš„ â€œéŸ³æ¨‚å¥³ç¥â€ã€Œç¹†æ–¯ã€ç™»å ´   zh-TW\n",
            "52667        å¤§ç«‹å…‰2450ç›¤ä¸­æ–°é«˜ å°è‚¡æ”¶æ¼²9520 http://t.co/T1x9EhD7mi                                      å¤§ç«‹å…‰ç›¤ä¸­æ–°é«˜ å°è‚¡æ”¶æ¼²   zh-TW\n",
            "52668                              @hundtw ä¸è¦çœ¯å•¦ ä¾†å–ä¸€æ¯å•¦ #å–‚                                       ä¸è¦çœ¯å•¦ ä¾†å–ä¸€æ¯å•¦ å–‚  zh-TW\n",
            "52669  - è³€æ–‡p14 å°ç£è¨ªå•ä½ åœ° å…¶ä»–æˆå“¡è©±ä½ ä¿‚å…¨éšŠæœ€å¤©ä¸æ€•åœ°ä¸æ€•æœé™£ æˆ‘æ—ï¼š å¦‚æœä½ å»æ‹å¢æ³• ...   è³€æ–‡p å°ç£è¨ªå•ä½ åœ° å…¶ä»–æˆå“¡è©±ä½ ä¿‚å…¨éšŠæœ€å¤©ä¸æ€•åœ°ä¸æ€•æœé™£ æˆ‘æ—ï¼š å¦‚æœä½ å»æ‹å¢æ³• æœƒå””æœƒ...  zh-TW\n",
            "---\n",
            "Empty DataFrame\n",
            "Columns: [tweet, tweet, label]\n",
            "Index: []\n",
            "---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ht7tAk-r5Re8"
      },
      "source": [
        "cleaned_dataset = clean_data(dataset, TARGET_COLUMN)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wHvLCaLVJAoo",
        "outputId": "36bc6917-53d4-4c34-8212-c03d6ed22962"
      },
      "source": [
        "cleaned_dataset.isnull().values.any() # Dataset does not contain any rows with null values"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "go29EMqShzcu"
      },
      "source": [
        "### 4.Data Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8qkq-4MKosP"
      },
      "source": [
        "def back_translation(df,target_languages=['en']):\n",
        "  translated_data = pd.DataFrame(columns={TWEET_COLUMN, TARGET_COLUMN})\n",
        "  for target_language in target_languages:\n",
        "    for index, row in df.iterrows():\n",
        "      try:\n",
        "        tweet = row['tweet']\n",
        "        source_language = row['label']\n",
        "        translated_data=translated_data.append({'tweet': translator.translate(translator.translate(tweet, dest=target_language).text, dest=source_language).text, 'label': source_language}, ignore_index=True)\n",
        "      except Exception as e:\n",
        "        print(e)\n",
        "        pass\n",
        "  return translated_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3iev8EdrRQG2",
        "outputId": "4e74d850-b63e-4ce5-fa9c-f2ebf3a0b405"
      },
      "source": [
        "print_number_of_underrepresented_languages(cleaned_dataset, TARGET_COLUMN, SAMPLE_THRESHOLD)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 50 languages in this data set with less then 20 samples.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iPZhejNxdCFn",
        "outputId": "517114ac-460c-4576-d29c-12b6ad10c5d0"
      },
      "source": [
        "underrepresented_languages = get_underrepresented_languages(cleaned_dataset, TARGET_COLUMN, SAMPLE_THRESHOLD)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['arlatn', 'az', 'bg', 'bn', 'bs', 'cs', 'cy', 'da', 'dv', 'et', 'eu', 'gl', 'ha', 'hilatn', 'hr', 'ht', 'hu', 'hy', 'is', 'jalatn', 'jv', 'km', 'kolatn', 'la', 'lv', 'mk', 'mn', 'mr', 'ne', 'no', 'ps', 'pslatn', 'ro', 'si', 'sk', 'sl', 'sq', 'su', 'sw', 'ta', 'talatn', 'tn', 'uk', 'ur', 'urlatn', 'wo', 'xh', 'yo', 'zhtw', 'zu']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "amnYMOOJ1xRA",
        "outputId": "fb54837c-ace7-4e0b-c5ea-068d3aa4a5b8"
      },
      "source": [
        "upsampled_dataset = cleaned_dataset.copy()\n",
        "for l in underrepresented_languages:\n",
        "  if not l.endswith('latn'): \n",
        "    continue #skip latn languages because they dont work with back translation\n",
        "  underrepresented_language = upsampled_dataset[upsampled_dataset[TARGET_COLUMN]==l]\n",
        "  upsampled_dataset.drop(upsampled_dataset[upsampled_dataset[TARGET_COLUMN]==l].index, inplace = True, axis=0)\n",
        "  len_first = len(underrepresented_language)\n",
        "  if not l.endswith('latn'): #skip latn languages because they dont work with back translation\n",
        "    underrepresented_language = pd.concat([underrepresented_language, back_translation(underrepresented_language)], axis=0)\n",
        "  len_second = len(underrepresented_language)\n",
        "  if(len_second < SAMPLE_THRESHOLD):\n",
        "    underrepresented_language = resample(underrepresented_language, n_samples=SAMPLE_THRESHOLD)\n",
        "  len_third = len(underrepresented_language)\n",
        "  print(\"({0}): #{1}=>back_translation=>#{2}=>resampling=>#{3}\".format(l, len_first, len_second, len_third))\n",
        "  upsampled_dataset = pd.concat([upsampled_dataset, underrepresented_language], axis=0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "arlatn\n",
            "az\n",
            "(az): #3=>back_translation=>#6=>resampling=>#20\n",
            "bg\n",
            "(bg): #4=>back_translation=>#8=>resampling=>#20\n",
            "bn\n",
            "(bn): #8=>back_translation=>#16=>resampling=>#20\n",
            "bs\n",
            "(bs): #5=>back_translation=>#10=>resampling=>#20\n",
            "cs\n",
            "(cs): #5=>back_translation=>#10=>resampling=>#20\n",
            "cy\n",
            "(cy): #1=>back_translation=>#2=>resampling=>#20\n",
            "da\n",
            "(da): #8=>back_translation=>#16=>resampling=>#20\n",
            "dv\n",
            "invalid destination language\n",
            "(dv): #1=>back_translation=>#1=>resampling=>#20\n",
            "et\n",
            "(et): #2=>back_translation=>#4=>resampling=>#20\n",
            "eu\n",
            "(eu): #2=>back_translation=>#4=>resampling=>#20\n",
            "gl\n",
            "(gl): #3=>back_translation=>#6=>resampling=>#20\n",
            "ha\n",
            "(ha): #1=>back_translation=>#2=>resampling=>#20\n",
            "hilatn\n",
            "hr\n",
            "(hr): #6=>back_translation=>#12=>resampling=>#20\n",
            "ht\n",
            "(ht): #3=>back_translation=>#6=>resampling=>#20\n",
            "hu\n",
            "(hu): #15=>back_translation=>#30=>resampling=>#30\n",
            "hy\n",
            "(hy): #2=>back_translation=>#4=>resampling=>#20\n",
            "is\n",
            "(is): #1=>back_translation=>#2=>resampling=>#20\n",
            "jalatn\n",
            "jv\n",
            "invalid destination language\n",
            "invalid destination language\n",
            "invalid destination language\n",
            "invalid destination language\n",
            "invalid destination language\n",
            "invalid destination language\n",
            "invalid destination language\n",
            "invalid destination language\n",
            "invalid destination language\n",
            "invalid destination language\n",
            "invalid destination language\n",
            "(jv): #11=>back_translation=>#11=>resampling=>#20\n",
            "km\n",
            "(km): #3=>back_translation=>#6=>resampling=>#20\n",
            "kolatn\n",
            "la\n",
            "(la): #1=>back_translation=>#2=>resampling=>#20\n",
            "lv\n",
            "(lv): #5=>back_translation=>#10=>resampling=>#20\n",
            "mk\n",
            "(mk): #1=>back_translation=>#2=>resampling=>#20\n",
            "mn\n",
            "(mn): #1=>back_translation=>#2=>resampling=>#20\n",
            "mr\n",
            "(mr): #1=>back_translation=>#2=>resampling=>#20\n",
            "ne\n",
            "(ne): #5=>back_translation=>#10=>resampling=>#20\n",
            "no\n",
            "(no): #12=>back_translation=>#24=>resampling=>#24\n",
            "ps\n",
            "(ps): #1=>back_translation=>#2=>resampling=>#20\n",
            "pslatn\n",
            "ro\n",
            "(ro): #14=>back_translation=>#28=>resampling=>#28\n",
            "si\n",
            "(si): #1=>back_translation=>#2=>resampling=>#20\n",
            "sk\n",
            "(sk): #1=>back_translation=>#2=>resampling=>#20\n",
            "sl\n",
            "(sl): #2=>back_translation=>#4=>resampling=>#20\n",
            "sq\n",
            "(sq): #9=>back_translation=>#18=>resampling=>#20\n",
            "su\n",
            "(su): #10=>back_translation=>#20=>resampling=>#20\n",
            "sw\n",
            "(sw): #8=>back_translation=>#16=>resampling=>#20\n",
            "ta\n",
            "(ta): #12=>back_translation=>#24=>resampling=>#24\n",
            "talatn\n",
            "tn\n",
            "invalid destination language\n",
            "(tn): #1=>back_translation=>#1=>resampling=>#20\n",
            "uk\n",
            "(uk): #18=>back_translation=>#36=>resampling=>#36\n",
            "ur\n",
            "(ur): #12=>back_translation=>#24=>resampling=>#24\n",
            "urlatn\n",
            "wo\n",
            "invalid destination language\n",
            "(wo): #1=>back_translation=>#1=>resampling=>#20\n",
            "xh\n",
            "(xh): #2=>back_translation=>#4=>resampling=>#20\n",
            "yo\n",
            "(yo): #1=>back_translation=>#2=>resampling=>#20\n",
            "zhtw\n",
            "invalid destination language\n",
            "invalid destination language\n",
            "invalid destination language\n",
            "invalid destination language\n",
            "invalid destination language\n",
            "invalid destination language\n",
            "invalid destination language\n",
            "invalid destination language\n",
            "invalid destination language\n",
            "invalid destination language\n",
            "invalid destination language\n",
            "invalid destination language\n",
            "invalid destination language\n",
            "invalid destination language\n",
            "(zhtw): #14=>back_translation=>#14=>resampling=>#20\n",
            "zu\n",
            "(zu): #1=>back_translation=>#2=>resampling=>#20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "id": "mM5NKgHNjdKp",
        "outputId": "5870b01d-3f7f-4bbd-c036-d9778201102e"
      },
      "source": [
        "upsampled_dataset.reset_index(drop=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Anyone goin to the rope swing?</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>No fue fÃ¡cil pero valiÃ³ la pena.</td>\n",
              "      <td>es</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>@jochortega es plaga el lala jajajaja</td>\n",
              "      <td>es</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ç‰¹é€²ã®æ ¡èˆã®ãƒˆã‚¤ãƒ¬ã¯ã‚¦ã‚©ã‚·ãƒ¥ãƒ¬ãƒƒãƒˆãŒã¤ã„ã¦ã„ã¦ç¾¨ã¾ã—ã„</td>\n",
              "      <td>ja</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ë‘ ëˆˆì„ ê°ì€ ì´ìœ ê°€, ëˆ„êµ¬ë•Œë¬¸ë„ ì•„ë‹ˆê¸°ë¥¼...</td>\n",
              "      <td>ko</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67637</th>\n",
              "      <td>@Official_SABC1 Moloooo nakuwe!!!</td>\n",
              "      <td>zu</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67638</th>\n",
              "      <td>@Official_SABC1 Moloooo nakuwe!!!</td>\n",
              "      <td>zu</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67639</th>\n",
              "      <td>@Official_SABC1 Moloooo nakuwe!!!</td>\n",
              "      <td>zu</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67640</th>\n",
              "      <td>@Official_SABC1 Moloooo nakuwe!!!</td>\n",
              "      <td>zu</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67641</th>\n",
              "      <td>@ Official_SABC1 Molooo nawe !!!</td>\n",
              "      <td>zu</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>67642 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                       tweet label\n",
              "0             Anyone goin to the rope swing?    en\n",
              "1           No fue fÃ¡cil pero valiÃ³ la pena.    es\n",
              "2      @jochortega es plaga el lala jajajaja    es\n",
              "3                ç‰¹é€²ã®æ ¡èˆã®ãƒˆã‚¤ãƒ¬ã¯ã‚¦ã‚©ã‚·ãƒ¥ãƒ¬ãƒƒãƒˆãŒã¤ã„ã¦ã„ã¦ç¾¨ã¾ã—ã„    ja\n",
              "4                 ë‘ ëˆˆì„ ê°ì€ ì´ìœ ê°€, ëˆ„êµ¬ë•Œë¬¸ë„ ì•„ë‹ˆê¸°ë¥¼...    ko\n",
              "...                                      ...   ...\n",
              "67637      @Official_SABC1 Moloooo nakuwe!!!    zu\n",
              "67638      @Official_SABC1 Moloooo nakuwe!!!    zu\n",
              "67639      @Official_SABC1 Moloooo nakuwe!!!    zu\n",
              "67640      @Official_SABC1 Moloooo nakuwe!!!    zu\n",
              "67641       @ Official_SABC1 Molooo nawe !!!    zu\n",
              "\n",
              "[67642 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jR2fpoJ3iyN3"
      },
      "source": [
        "upsampled_dataset.to_pickle('./dataset.pkl')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nc9DsPayjCU9"
      },
      "source": [
        "upsampled_dataset.to_csv('./dataset.csv', header=True, index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cPZANQdPhavy",
        "outputId": "a7f39c69-f658-4dae-cde9-fc122fb9b9c0"
      },
      "source": [
        "get_underrepresented_languages(upsampled_dataset, TARGET_COLUMN, SAMPLE_THRESHOLD)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qaFPH8EA2CdR",
        "outputId": "e0456aa5-ee18-4b1b-e7f6-b9f0d0c2b4dd"
      },
      "source": [
        "print_number_of_underrepresented_languages(upsampled_dataset, TARGET_COLUMN, SAMPLE_THRESHOLD)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 0 languages in this data set with less then 20 samples.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HCXkJaGzhJB7"
      },
      "source": [
        "#for l in underrepresented_languages:\n",
        "#  underrepresented_language = upsampled_dataset[upsampled_dataset[TARGET_COLUMN]==l]\n",
        "#  underrepresented_language = resample(underrepresented_language, n_samples=SAMPLE_THRESHOLD)\n",
        "#  upsampled_dataset = pd.concat([upsampled_dataset, underrepresented_language], axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yvvbKuzu-3XL",
        "outputId": "93cb3db1-4650-44b0-f499-424818244b9a"
      },
      "source": [
        "print(\"The length of the upsampled dataset is {}\".format(len(upsampled_dataset)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The length of the upsampled dataset is 67642\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iMTSM4istMQw"
      },
      "source": [
        "## 2. Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6oyQ6eZbCeUX"
      },
      "source": [
        "TARGET_COLUMN = 'label'\n",
        "TWEET_COLUMN = 'tweet'\n",
        "dataset=upsampled_dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tbNPDezQCVpH"
      },
      "source": [
        "X = dataset[TWEET_COLUMN]\n",
        "y = dataset[TARGET_COLUMN]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5xIWW6ZqKPKH"
      },
      "source": [
        "# Vectorize with ngram_range 1 to 3\n",
        "vectorizer = TfidfVectorizer(analyzer='char', ngram_range=(1,3))\n",
        "X_train_vec = vectorizer.fit_transform(X_train)\n",
        "X_test_vec = vectorizer.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7d7udC4tUb3v",
        "outputId": "c78a5a4c-073b-47df-a01b-0b66e5986383"
      },
      "source": [
        "print(type(X_train_vec))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'scipy.sparse.csr.csr_matrix'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0UfmSwvltMRQ"
      },
      "source": [
        "## 3. Model Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L0zdPLMHJ2AV"
      },
      "source": [
        "# All parameters we are individually testing\n",
        "# If the computational power would be high enough we could\n",
        "# use GridSearchCV to easily find the best hyperparameters\n",
        "# However running this grid search CV exceeds colabs max runtime.\n",
        "parameters = {\n",
        "        'hidden_layer_sizes': [100, 500],\n",
        "        'solver': ['adam', 'sgd'],\n",
        "        'activation': ['tanh', 'relu'],\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "38nb7mqEL9Ve"
      },
      "source": [
        "\n",
        "## hidden_layer_sizes=(100): configuration 1-4\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mUP9_D47N0Ed"
      },
      "source": [
        "### Configuration 01"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "8gq1DtZktMRR",
        "outputId": "5725af1c-99c0-4448-ab2c-d9513731d892"
      },
      "source": [
        "mlp_clf = MLPClassifier(early_stopping=True, hidden_layer_sizes=(100), solver='adam', activation='tanh', max_iter=100, verbose=True)\n",
        "mlp_clf.fit(X_train_vec, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 1.35136123\n",
            "Validation score: 0.864488\n",
            "Iteration 2, loss = 0.38750770\n",
            "Validation score: 0.898160\n",
            "Iteration 3, loss = 0.20907587\n",
            "Validation score: 0.912779\n",
            "Iteration 4, loss = 0.12316765\n",
            "Validation score: 0.914586\n",
            "Iteration 5, loss = 0.07781613\n",
            "Validation score: 0.918857\n",
            "Iteration 6, loss = 0.05258100\n",
            "Validation score: 0.919021\n",
            "Iteration 7, loss = 0.03794585\n",
            "Validation score: 0.919678\n",
            "Iteration 8, loss = 0.02905713\n",
            "Validation score: 0.919021\n",
            "Iteration 9, loss = 0.02351217\n",
            "Validation score: 0.918693\n",
            "Iteration 10, loss = 0.01983701\n",
            "Validation score: 0.916064\n",
            "Iteration 11, loss = 0.01737863\n",
            "Validation score: 0.917050\n",
            "Iteration 12, loss = 0.01551853\n",
            "Validation score: 0.917050\n",
            "Iteration 13, loss = 0.01421724\n",
            "Validation score: 0.915243\n",
            "Iteration 14, loss = 0.01312494\n",
            "Validation score: 0.915079\n",
            "Iteration 15, loss = 0.01225299\n",
            "Validation score: 0.914586\n",
            "Iteration 16, loss = 0.01154947\n",
            "Validation score: 0.914750\n",
            "Iteration 17, loss = 0.01087968\n",
            "Validation score: 0.915900\n",
            "Iteration 18, loss = 0.01028974\n",
            "Validation score: 0.914093\n",
            "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "MLPClassifier(activation='tanh', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
              "              beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
              "              hidden_layer_sizes=100, learning_rate='constant',\n",
              "              learning_rate_init=0.001, max_fun=15000, max_iter=100,\n",
              "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
              "              power_t=0.5, random_state=None, shuffle=True, solver='adam',\n",
              "              tol=0.0001, validation_fraction=0.1, verbose=True,\n",
              "              warm_start=False)"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VuUJKblKM87g",
        "outputId": "efa08744-19cf-4021-9344-d187559aa5ba"
      },
      "source": [
        "print(classification_report(y_test, mlp_clf.predict(X_test_vec)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "          ar       0.98      0.98      0.98       256\n",
            "      arlatn       1.00      1.00      1.00         1\n",
            "          az       1.00      1.00      1.00        10\n",
            "          bg       1.00      1.00      1.00         2\n",
            "          bn       1.00      1.00      1.00         5\n",
            "          bs       1.00      1.00      1.00        11\n",
            "          ca       0.00      0.00      0.00         4\n",
            "          cs       1.00      1.00      1.00         4\n",
            "          cy       1.00      1.00      1.00         3\n",
            "          da       1.00      1.00      1.00         4\n",
            "          de       1.00      0.79      0.88        28\n",
            "          dv       1.00      1.00      1.00         8\n",
            "          el       1.00      0.80      0.89         5\n",
            "          en       0.93      0.97      0.95      2357\n",
            "          es       0.92      0.95      0.93       728\n",
            "          et       1.00      1.00      1.00         3\n",
            "          eu       1.00      1.00      1.00         3\n",
            "          fa       1.00      0.33      0.50         3\n",
            "          fi       1.00      0.50      0.67         4\n",
            "          fr       0.94      0.84      0.89       111\n",
            "          gl       1.00      1.00      1.00         1\n",
            "          ha       1.00      1.00      1.00         3\n",
            "          he       1.00      1.00      1.00         2\n",
            "          hi       1.00      0.67      0.80         3\n",
            "          hr       1.00      1.00      1.00         5\n",
            "          ht       1.00      1.00      1.00         5\n",
            "          hu       1.00      0.60      0.75         5\n",
            "          hy       1.00      1.00      1.00         5\n",
            "          id       0.87      0.88      0.88       385\n",
            "          is       1.00      1.00      1.00         5\n",
            "          it       0.96      0.67      0.79        39\n",
            "          ja       0.99      0.99      0.99      1269\n",
            "      jalatn       1.00      1.00      1.00         3\n",
            "          jv       1.00      0.80      0.89         5\n",
            "          km       1.00      1.00      1.00         6\n",
            "          ko       1.00      0.83      0.90        63\n",
            "      kolatn       1.00      1.00      1.00         3\n",
            "          la       1.00      1.00      1.00         3\n",
            "          lv       1.00      1.00      1.00         2\n",
            "          mk       1.00      1.00      1.00         3\n",
            "          mn       1.00      1.00      1.00         1\n",
            "          mr       1.00      1.00      1.00         2\n",
            "          ms       0.75      0.18      0.29        17\n",
            "          ne       1.00      1.00      1.00         6\n",
            "          nl       0.86      0.82      0.84        22\n",
            "          no       1.00      0.75      0.86         4\n",
            "          pl       0.86      0.67      0.75         9\n",
            "          ps       1.00      1.00      1.00         5\n",
            "      pslatn       1.00      1.00      1.00         4\n",
            "          pt       0.94      0.92      0.93       347\n",
            "          ro       1.00      0.80      0.89         5\n",
            "          ru       0.98      0.98      0.98       126\n",
            "          si       1.00      1.00      1.00         2\n",
            "          sk       1.00      1.00      1.00         4\n",
            "          sl       1.00      1.00      1.00         5\n",
            "          sq       1.00      1.00      1.00         4\n",
            "          sr       0.00      0.00      0.00         5\n",
            "          su       1.00      0.50      0.67         2\n",
            "          sv       1.00      0.67      0.80         6\n",
            "          sw       1.00      1.00      1.00         6\n",
            "          ta       1.00      1.00      1.00         4\n",
            "      talatn       1.00      1.00      1.00         2\n",
            "          th       1.00      0.97      0.98        63\n",
            "          tl       0.83      0.69      0.75        35\n",
            "          tn       1.00      1.00      1.00         5\n",
            "          tr       0.94      0.85      0.89        74\n",
            "          uk       1.00      0.80      0.89         5\n",
            "         und       0.66      0.66      0.66       595\n",
            "          ur       1.00      1.00      1.00         3\n",
            "      urlatn       1.00      0.50      0.67         2\n",
            "          vi       1.00      0.33      0.50         3\n",
            "          wo       1.00      1.00      1.00         4\n",
            "          xh       1.00      1.00      1.00         5\n",
            "          yo       1.00      1.00      1.00         2\n",
            "        zhcn       0.00      0.00      0.00         5\n",
            "        zhtw       1.00      1.00      1.00         6\n",
            "          zu       1.00      1.00      1.00         5\n",
            "\n",
            "    accuracy                           0.92      6765\n",
            "   macro avg       0.94      0.85      0.88      6765\n",
            "weighted avg       0.92      0.92      0.92      6765\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jk380eGhN-IF"
      },
      "source": [
        "### Configuration 02"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O4aSvJzFN-IG",
        "outputId": "b0f4e5b8-b025-4eb2-edb9-a805c8db442c"
      },
      "source": [
        "mlp_clf = MLPClassifier(early_stopping=True, hidden_layer_sizes=(100), solver='adam', activation='relu', max_iter=100, verbose=True)\n",
        "mlp_clf.fit(X_train_vec, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 1.44080992\n",
            "Validation score: 0.869087\n",
            "Iteration 2, loss = 0.40336973\n",
            "Validation score: 0.904895\n",
            "Iteration 3, loss = 0.22184401\n",
            "Validation score: 0.920828\n",
            "Iteration 4, loss = 0.13248716\n",
            "Validation score: 0.926248\n",
            "Iteration 5, loss = 0.08481837\n",
            "Validation score: 0.926577\n",
            "Iteration 6, loss = 0.05784939\n",
            "Validation score: 0.926413\n",
            "Iteration 7, loss = 0.04195377\n",
            "Validation score: 0.926248\n",
            "Iteration 8, loss = 0.03211862\n",
            "Validation score: 0.927070\n",
            "Iteration 9, loss = 0.02582995\n",
            "Validation score: 0.925756\n",
            "Iteration 10, loss = 0.02167531\n",
            "Validation score: 0.924606\n",
            "Iteration 11, loss = 0.01884304\n",
            "Validation score: 0.925099\n",
            "Iteration 12, loss = 0.01690268\n",
            "Validation score: 0.924770\n",
            "Iteration 13, loss = 0.01537346\n",
            "Validation score: 0.924606\n",
            "Iteration 14, loss = 0.01423894\n",
            "Validation score: 0.924606\n",
            "Iteration 15, loss = 0.01328507\n",
            "Validation score: 0.924934\n",
            "Iteration 16, loss = 0.01248132\n",
            "Validation score: 0.924934\n",
            "Iteration 17, loss = 0.01183086\n",
            "Validation score: 0.923784\n",
            "Iteration 18, loss = 0.01130216\n",
            "Validation score: 0.925263\n",
            "Iteration 19, loss = 0.01067333\n",
            "Validation score: 0.924606\n",
            "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
              "              beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
              "              hidden_layer_sizes=100, learning_rate='constant',\n",
              "              learning_rate_init=0.001, max_fun=15000, max_iter=100,\n",
              "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
              "              power_t=0.5, random_state=None, shuffle=True, solver='adam',\n",
              "              tol=0.0001, validation_fraction=0.1, verbose=True,\n",
              "              warm_start=False)"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4kBnRu9BOU9G",
        "outputId": "992b091f-6b79-4300-a70c-57ec513104a6"
      },
      "source": [
        "print(classification_report(y_test, mlp_clf.predict(X_test_vec)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "          ar       0.98      0.97      0.98       256\n",
            "      arlatn       1.00      1.00      1.00         1\n",
            "          az       1.00      1.00      1.00        10\n",
            "          bg       1.00      1.00      1.00         2\n",
            "          bn       1.00      1.00      1.00         5\n",
            "          bs       1.00      1.00      1.00        11\n",
            "          ca       0.00      0.00      0.00         4\n",
            "          cs       1.00      1.00      1.00         4\n",
            "          cy       1.00      1.00      1.00         3\n",
            "          da       1.00      1.00      1.00         4\n",
            "          de       1.00      0.82      0.90        28\n",
            "          dv       1.00      1.00      1.00         8\n",
            "          el       1.00      0.80      0.89         5\n",
            "          en       0.93      0.96      0.95      2357\n",
            "          es       0.92      0.95      0.94       728\n",
            "          et       1.00      1.00      1.00         3\n",
            "          eu       1.00      1.00      1.00         3\n",
            "          fa       1.00      0.33      0.50         3\n",
            "          fi       1.00      0.50      0.67         4\n",
            "          fr       0.94      0.84      0.89       111\n",
            "          gl       1.00      1.00      1.00         1\n",
            "          ha       1.00      1.00      1.00         3\n",
            "          he       1.00      1.00      1.00         2\n",
            "          hi       1.00      0.67      0.80         3\n",
            "          hr       1.00      1.00      1.00         5\n",
            "          ht       1.00      1.00      1.00         5\n",
            "          hu       1.00      0.80      0.89         5\n",
            "          hy       1.00      1.00      1.00         5\n",
            "          id       0.88      0.88      0.88       385\n",
            "          is       1.00      1.00      1.00         5\n",
            "          it       0.96      0.64      0.77        39\n",
            "          ja       0.99      0.99      0.99      1269\n",
            "      jalatn       1.00      1.00      1.00         3\n",
            "          jv       1.00      0.80      0.89         5\n",
            "          km       1.00      1.00      1.00         6\n",
            "          ko       1.00      0.81      0.89        63\n",
            "      kolatn       1.00      1.00      1.00         3\n",
            "          la       1.00      1.00      1.00         3\n",
            "          lv       1.00      1.00      1.00         2\n",
            "          mk       1.00      1.00      1.00         3\n",
            "          mn       1.00      1.00      1.00         1\n",
            "          mr       1.00      1.00      1.00         2\n",
            "          ms       0.62      0.29      0.40        17\n",
            "          ne       1.00      1.00      1.00         6\n",
            "          nl       0.83      0.68      0.75        22\n",
            "          no       1.00      0.75      0.86         4\n",
            "          pl       0.83      0.56      0.67         9\n",
            "          ps       1.00      1.00      1.00         5\n",
            "      pslatn       1.00      1.00      1.00         4\n",
            "          pt       0.94      0.91      0.92       347\n",
            "          ro       1.00      0.80      0.89         5\n",
            "          ru       0.98      0.98      0.98       126\n",
            "          si       1.00      1.00      1.00         2\n",
            "          sk       1.00      1.00      1.00         4\n",
            "          sl       1.00      1.00      1.00         5\n",
            "          sq       1.00      1.00      1.00         4\n",
            "          sr       0.00      0.00      0.00         5\n",
            "          su       1.00      0.50      0.67         2\n",
            "          sv       1.00      0.50      0.67         6\n",
            "          sw       1.00      1.00      1.00         6\n",
            "          ta       1.00      1.00      1.00         4\n",
            "      talatn       1.00      1.00      1.00         2\n",
            "          th       1.00      0.97      0.98        63\n",
            "          tl       0.81      0.71      0.76        35\n",
            "          tn       1.00      1.00      1.00         5\n",
            "          tr       0.96      0.86      0.91        74\n",
            "          uk       1.00      1.00      1.00         5\n",
            "         und       0.66      0.68      0.67       595\n",
            "          ur       1.00      0.67      0.80         3\n",
            "      urlatn       1.00      1.00      1.00         2\n",
            "          vi       1.00      0.33      0.50         3\n",
            "          wo       1.00      1.00      1.00         4\n",
            "          xh       1.00      1.00      1.00         5\n",
            "          yo       1.00      1.00      1.00         2\n",
            "        zhcn       0.00      0.00      0.00         5\n",
            "        zhtw       1.00      1.00      1.00         6\n",
            "          zu       1.00      1.00      1.00         5\n",
            "\n",
            "    accuracy                           0.92      6765\n",
            "   macro avg       0.94      0.86      0.89      6765\n",
            "weighted avg       0.92      0.92      0.92      6765\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_mkAJzofOEq2"
      },
      "source": [
        "### Configuration 03"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "0uFzCjU5OEq3",
        "outputId": "bafb7a36-7fdb-49f0-e450-26b7e3f79225"
      },
      "source": [
        "mlp_clf = MLPClassifier(early_stopping=True, hidden_layer_sizes=(100), solver='sgd', activation='tanh', max_iter=100, verbose=True)\n",
        "mlp_clf.fit(X_train_vec, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 3.83790675\n",
            "Validation score: 0.346091\n",
            "Iteration 2, loss = 2.80005137\n",
            "Validation score: 0.346091\n",
            "Iteration 3, loss = 2.43424634\n",
            "Validation score: 0.346091\n",
            "Iteration 4, loss = 2.29328226\n",
            "Validation score: 0.346091\n",
            "Iteration 5, loss = 2.21992028\n",
            "Validation score: 0.346091\n",
            "Iteration 6, loss = 2.16930773\n",
            "Validation score: 0.366130\n",
            "Iteration 7, loss = 2.12569797\n",
            "Validation score: 0.480289\n",
            "Iteration 8, loss = 2.08346862\n",
            "Validation score: 0.515769\n",
            "Iteration 9, loss = 2.04120553\n",
            "Validation score: 0.526938\n",
            "Iteration 10, loss = 1.99883010\n",
            "Validation score: 0.530388\n",
            "Iteration 11, loss = 1.95691272\n",
            "Validation score: 0.529074\n",
            "Iteration 12, loss = 1.91601130\n",
            "Validation score: 0.528581\n",
            "Iteration 13, loss = 1.87660695\n",
            "Validation score: 0.527431\n",
            "Iteration 14, loss = 1.83893518\n",
            "Validation score: 0.527102\n",
            "Iteration 15, loss = 1.80301735\n",
            "Validation score: 0.527102\n",
            "Iteration 16, loss = 1.76876771\n",
            "Validation score: 0.525953\n",
            "Iteration 17, loss = 1.73596789\n",
            "Validation score: 0.527267\n",
            "Iteration 18, loss = 1.70438489\n",
            "Validation score: 0.529895\n",
            "Iteration 19, loss = 1.67385303\n",
            "Validation score: 0.537451\n",
            "Iteration 20, loss = 1.64443073\n",
            "Validation score: 0.543857\n",
            "Iteration 21, loss = 1.61577152\n",
            "Validation score: 0.553548\n",
            "Iteration 22, loss = 1.58799018\n",
            "Validation score: 0.568495\n",
            "Iteration 23, loss = 1.56103380\n",
            "Validation score: 0.580979\n",
            "Iteration 24, loss = 1.53489508\n",
            "Validation score: 0.597076\n",
            "Iteration 25, loss = 1.50966422\n",
            "Validation score: 0.606110\n",
            "Iteration 26, loss = 1.48528117\n",
            "Validation score: 0.616787\n",
            "Iteration 27, loss = 1.46186302\n",
            "Validation score: 0.624507\n",
            "Iteration 28, loss = 1.43935293\n",
            "Validation score: 0.632227\n",
            "Iteration 29, loss = 1.41783294\n",
            "Validation score: 0.637484\n",
            "Iteration 30, loss = 1.39721355\n",
            "Validation score: 0.642083\n",
            "Iteration 31, loss = 1.37756498\n",
            "Validation score: 0.647339\n",
            "Iteration 32, loss = 1.35879851\n",
            "Validation score: 0.650953\n",
            "Iteration 33, loss = 1.34093833\n",
            "Validation score: 0.655716\n",
            "Iteration 34, loss = 1.32392275\n",
            "Validation score: 0.659987\n",
            "Iteration 35, loss = 1.30766425\n",
            "Validation score: 0.661137\n",
            "Iteration 36, loss = 1.29219057\n",
            "Validation score: 0.671485\n",
            "Iteration 37, loss = 1.27740079\n",
            "Validation score: 0.676413\n",
            "Iteration 38, loss = 1.26325136\n",
            "Validation score: 0.680519\n",
            "Iteration 39, loss = 1.24975294\n",
            "Validation score: 0.685283\n",
            "Iteration 40, loss = 1.23678184\n",
            "Validation score: 0.688732\n",
            "Iteration 41, loss = 1.22434442\n",
            "Validation score: 0.693988\n",
            "Iteration 42, loss = 1.21235271\n",
            "Validation score: 0.698095\n",
            "Iteration 43, loss = 1.20080773\n",
            "Validation score: 0.701544\n",
            "Iteration 44, loss = 1.18971234\n",
            "Validation score: 0.706472\n",
            "Iteration 45, loss = 1.17896182\n",
            "Validation score: 0.710414\n",
            "Iteration 46, loss = 1.16858059\n",
            "Validation score: 0.712385\n",
            "Iteration 47, loss = 1.15852927\n",
            "Validation score: 0.717148\n",
            "Iteration 48, loss = 1.14877519\n",
            "Validation score: 0.719284\n",
            "Iteration 49, loss = 1.13932871\n",
            "Validation score: 0.720762\n",
            "Iteration 50, loss = 1.13012600\n",
            "Validation score: 0.724869\n",
            "Iteration 51, loss = 1.12123430\n",
            "Validation score: 0.727497\n",
            "Iteration 52, loss = 1.11251944\n",
            "Validation score: 0.727661\n",
            "Iteration 53, loss = 1.10406905\n",
            "Validation score: 0.729632\n",
            "Iteration 54, loss = 1.09586074\n",
            "Validation score: 0.734888\n",
            "Iteration 55, loss = 1.08782374\n",
            "Validation score: 0.735381\n",
            "Iteration 56, loss = 1.08001231\n",
            "Validation score: 0.738502\n",
            "Iteration 57, loss = 1.07240383\n",
            "Validation score: 0.741459\n",
            "Iteration 58, loss = 1.06496062\n",
            "Validation score: 0.743922\n",
            "Iteration 59, loss = 1.05770561\n",
            "Validation score: 0.745237\n",
            "Iteration 60, loss = 1.05062061\n",
            "Validation score: 0.747208\n",
            "Iteration 61, loss = 1.04374049\n",
            "Validation score: 0.747700\n",
            "Iteration 62, loss = 1.03699385\n",
            "Validation score: 0.750657\n",
            "Iteration 63, loss = 1.03038835\n",
            "Validation score: 0.752792\n",
            "Iteration 64, loss = 1.02396438\n",
            "Validation score: 0.753942\n",
            "Iteration 65, loss = 1.01769635\n",
            "Validation score: 0.755420\n",
            "Iteration 66, loss = 1.01154920\n",
            "Validation score: 0.757556\n",
            "Iteration 67, loss = 1.00555981\n",
            "Validation score: 0.758049\n",
            "Iteration 68, loss = 0.99966179\n",
            "Validation score: 0.759198\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Urcbii6kigaj",
        "outputId": "8efcb260-7c07-4d1a-8df8-df0a6eef20e4"
      },
      "source": [
        "print(classification_report(y_test, mlp_clf.predict(X_test_vec)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "          ar       0.97      0.95      0.96       274\n",
            "      arlatn       0.00      0.00      0.00         5\n",
            "          az       0.00      0.00      0.00         5\n",
            "          bg       0.00      0.00      0.00         3\n",
            "          bn       0.00      0.00      0.00         2\n",
            "          bs       0.00      0.00      0.00         5\n",
            "          ca       0.00      0.00      0.00         3\n",
            "          cs       0.00      0.00      0.00         5\n",
            "          cy       0.00      0.00      0.00         5\n",
            "          da       0.00      0.00      0.00         1\n",
            "          de       0.00      0.00      0.00        19\n",
            "          dv       0.00      0.00      0.00         2\n",
            "          el       0.00      0.00      0.00         1\n",
            "          en       0.84      0.97      0.90      2355\n",
            "          es       0.67      0.90      0.77       763\n",
            "          et       0.00      0.00      0.00         4\n",
            "          eu       0.00      0.00      0.00         5\n",
            "          fi       0.00      0.00      0.00         2\n",
            "          fr       0.00      0.00      0.00       103\n",
            "          gl       0.00      0.00      0.00         2\n",
            "          ha       0.00      0.00      0.00         4\n",
            "          he       0.00      0.00      0.00         3\n",
            "          hi       0.00      0.00      0.00         1\n",
            "      hilatn       0.00      0.00      0.00         5\n",
            "          hr       0.00      0.00      0.00         8\n",
            "          ht       0.00      0.00      0.00         2\n",
            "          hu       0.00      0.00      0.00         5\n",
            "          hy       0.00      0.00      0.00         6\n",
            "          id       0.64      0.80      0.71       362\n",
            "          is       0.00      0.00      0.00         3\n",
            "          it       0.00      0.00      0.00        35\n",
            "          ja       0.87      0.97      0.91      1295\n",
            "      jalatn       0.00      0.00      0.00         2\n",
            "          jv       0.00      0.00      0.00         5\n",
            "          km       0.00      0.00      0.00         3\n",
            "          ko       0.00      0.00      0.00        53\n",
            "      kolatn       0.00      0.00      0.00         1\n",
            "          la       0.00      0.00      0.00         6\n",
            "          lv       0.00      0.00      0.00         6\n",
            "          mk       0.00      0.00      0.00         3\n",
            "          mn       0.00      0.00      0.00         6\n",
            "          mr       0.00      0.00      0.00         6\n",
            "          ms       0.00      0.00      0.00         9\n",
            "          ne       0.00      0.00      0.00         8\n",
            "          nl       0.00      0.00      0.00        30\n",
            "          no       0.00      0.00      0.00         2\n",
            "          pl       0.00      0.00      0.00        10\n",
            "          ps       0.00      0.00      0.00         4\n",
            "      pslatn       0.00      0.00      0.00         1\n",
            "          pt       0.93      0.19      0.31       349\n",
            "          ro       0.00      0.00      0.00         6\n",
            "          ru       0.88      0.79      0.83       124\n",
            "          si       0.00      0.00      0.00         6\n",
            "          sk       0.00      0.00      0.00         5\n",
            "          sl       0.00      0.00      0.00         4\n",
            "          sq       0.00      0.00      0.00         2\n",
            "          sr       0.00      0.00      0.00         5\n",
            "          su       0.00      0.00      0.00         7\n",
            "          sv       0.00      0.00      0.00        10\n",
            "          sw       0.00      0.00      0.00         3\n",
            "          ta       0.00      0.00      0.00         3\n",
            "      talatn       0.00      0.00      0.00         2\n",
            "          th       0.00      0.00      0.00        65\n",
            "          tl       0.00      0.00      0.00        55\n",
            "          tn       0.00      0.00      0.00         2\n",
            "          tr       0.00      0.00      0.00        80\n",
            "          uk       0.00      0.00      0.00         8\n",
            "         und       0.41      0.50      0.45       548\n",
            "          ur       0.00      0.00      0.00         4\n",
            "      urlatn       0.00      0.00      0.00         2\n",
            "          vi       0.00      0.00      0.00         3\n",
            "          wo       0.00      0.00      0.00         6\n",
            "          xh       0.00      0.00      0.00         5\n",
            "          yo       0.00      0.00      0.00         3\n",
            "        zhtw       0.00      0.00      0.00         5\n",
            "          zu       0.00      0.00      0.00         5\n",
            "\n",
            "    accuracy                           0.77      6765\n",
            "   macro avg       0.08      0.08      0.08      6765\n",
            "weighted avg       0.71      0.77      0.72      6765\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dy8NGueVOM5q"
      },
      "source": [
        "### Configuration 04"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xjKjeyXXOM5q",
        "outputId": "e6199608-83bc-4acf-d177-e209b2330308"
      },
      "source": [
        "mlp_clf = MLPClassifier(early_stopping=True, hidden_layer_sizes=(100), solver='sgd', activation='relu', max_iter=100, verbose=True)\n",
        "mlp_clf.fit(X_train_vec, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 4.02919301\n",
            "Validation score: 0.346748\n",
            "Iteration 2, loss = 3.14377492\n",
            "Validation score: 0.346748\n",
            "Iteration 3, loss = 2.56392484\n",
            "Validation score: 0.346748\n",
            "Iteration 4, loss = 2.35278089\n",
            "Validation score: 0.346748\n",
            "Iteration 5, loss = 2.26528485\n",
            "Validation score: 0.346748\n",
            "Iteration 6, loss = 2.21389089\n",
            "Validation score: 0.346748\n",
            "Iteration 7, loss = 2.17213758\n",
            "Validation score: 0.348883\n",
            "Iteration 8, loss = 2.13207392\n",
            "Validation score: 0.453515\n",
            "Iteration 9, loss = 2.09104169\n",
            "Validation score: 0.498357\n",
            "Iteration 10, loss = 2.04880234\n",
            "Validation score: 0.517247\n",
            "Iteration 11, loss = 2.00590778\n",
            "Validation score: 0.521189\n",
            "Iteration 12, loss = 1.96306010\n",
            "Validation score: 0.520696\n",
            "Iteration 13, loss = 1.92126695\n",
            "Validation score: 0.519054\n",
            "Iteration 14, loss = 1.88095186\n",
            "Validation score: 0.518397\n",
            "Iteration 15, loss = 1.84241353\n",
            "Validation score: 0.518233\n",
            "Iteration 16, loss = 1.80577731\n",
            "Validation score: 0.518068\n",
            "Iteration 17, loss = 1.77081258\n",
            "Validation score: 0.519218\n",
            "Iteration 18, loss = 1.73745917\n",
            "Validation score: 0.521189\n",
            "Iteration 19, loss = 1.70540344\n",
            "Validation score: 0.524967\n",
            "Iteration 20, loss = 1.67455771\n",
            "Validation score: 0.529566\n",
            "Iteration 21, loss = 1.64467251\n",
            "Validation score: 0.538601\n",
            "Iteration 22, loss = 1.61578854\n",
            "Validation score: 0.550099\n",
            "Iteration 23, loss = 1.58778501\n",
            "Validation score: 0.558804\n",
            "Iteration 24, loss = 1.56064452\n",
            "Validation score: 0.571124\n",
            "Iteration 25, loss = 1.53443847\n",
            "Validation score: 0.584264\n",
            "Iteration 26, loss = 1.50906186\n",
            "Validation score: 0.594941\n",
            "Iteration 27, loss = 1.48475539\n",
            "Validation score: 0.605289\n",
            "Iteration 28, loss = 1.46135115\n",
            "Validation score: 0.611695\n",
            "Iteration 29, loss = 1.43899993\n",
            "Validation score: 0.618594\n",
            "Iteration 30, loss = 1.41752904\n",
            "Validation score: 0.626807\n",
            "Iteration 31, loss = 1.39710464\n",
            "Validation score: 0.631735\n",
            "Iteration 32, loss = 1.37756625\n",
            "Validation score: 0.636827\n",
            "Iteration 33, loss = 1.35896542\n",
            "Validation score: 0.642904\n",
            "Iteration 34, loss = 1.34125814\n",
            "Validation score: 0.645696\n",
            "Iteration 35, loss = 1.32439846\n",
            "Validation score: 0.650460\n",
            "Iteration 36, loss = 1.30829094\n",
            "Validation score: 0.659001\n",
            "Iteration 37, loss = 1.29297601\n",
            "Validation score: 0.661794\n",
            "Iteration 38, loss = 1.27836837\n",
            "Validation score: 0.667871\n",
            "Iteration 39, loss = 1.26436781\n",
            "Validation score: 0.675920\n",
            "Iteration 40, loss = 1.25107209\n",
            "Validation score: 0.679698\n",
            "Iteration 41, loss = 1.23827764\n",
            "Validation score: 0.688239\n",
            "Iteration 42, loss = 1.22597316\n",
            "Validation score: 0.688568\n",
            "Iteration 43, loss = 1.21421455\n",
            "Validation score: 0.694809\n",
            "Iteration 44, loss = 1.20288021\n",
            "Validation score: 0.698259\n",
            "Iteration 45, loss = 1.19193738\n",
            "Validation score: 0.702037\n",
            "Iteration 46, loss = 1.18138379\n",
            "Validation score: 0.704172\n",
            "Iteration 47, loss = 1.17118849\n",
            "Validation score: 0.705979\n",
            "Iteration 48, loss = 1.16128318\n",
            "Validation score: 0.707786\n",
            "Iteration 49, loss = 1.15168758\n",
            "Validation score: 0.711235\n",
            "Iteration 50, loss = 1.14240475\n",
            "Validation score: 0.715177\n",
            "Iteration 51, loss = 1.13339869\n",
            "Validation score: 0.717477\n",
            "Iteration 52, loss = 1.12461737\n",
            "Validation score: 0.719777\n",
            "Iteration 53, loss = 1.11607600\n",
            "Validation score: 0.721255\n",
            "Iteration 54, loss = 1.10778021\n",
            "Validation score: 0.721912\n",
            "Iteration 55, loss = 1.09968494\n",
            "Validation score: 0.723883\n",
            "Iteration 56, loss = 1.09184158\n",
            "Validation score: 0.724540\n",
            "Iteration 57, loss = 1.08415567\n",
            "Validation score: 0.725690\n",
            "Iteration 58, loss = 1.07666505\n",
            "Validation score: 0.726511\n",
            "Iteration 59, loss = 1.06933136\n",
            "Validation score: 0.729304\n",
            "Iteration 60, loss = 1.06219828\n",
            "Validation score: 0.730453\n",
            "Iteration 61, loss = 1.05522855\n",
            "Validation score: 0.733903\n",
            "Iteration 62, loss = 1.04841870\n",
            "Validation score: 0.735381\n",
            "Iteration 63, loss = 1.04176983\n",
            "Validation score: 0.736859\n",
            "Iteration 64, loss = 1.03526080\n",
            "Validation score: 0.739159\n",
            "Iteration 65, loss = 1.02889163\n",
            "Validation score: 0.742444\n",
            "Iteration 66, loss = 1.02266797\n",
            "Validation score: 0.742773\n",
            "Iteration 67, loss = 1.01659430\n",
            "Validation score: 0.744251\n",
            "Iteration 68, loss = 1.01062949\n",
            "Validation score: 0.746879\n",
            "Iteration 69, loss = 1.00481937\n",
            "Validation score: 0.747865\n",
            "Iteration 70, loss = 0.99912205\n",
            "Validation score: 0.749671\n",
            "Iteration 71, loss = 0.99351362\n",
            "Validation score: 0.752464\n",
            "Iteration 72, loss = 0.98807280\n",
            "Validation score: 0.753614\n",
            "Iteration 73, loss = 0.98268432\n",
            "Validation score: 0.754271\n",
            "Iteration 74, loss = 0.97745743\n",
            "Validation score: 0.754763\n",
            "Iteration 75, loss = 0.97233744\n",
            "Validation score: 0.758870\n",
            "Iteration 76, loss = 0.96729777\n",
            "Validation score: 0.758870\n",
            "Iteration 77, loss = 0.96234634\n",
            "Validation score: 0.762319\n",
            "Iteration 78, loss = 0.95747945\n",
            "Validation score: 0.764619\n",
            "Iteration 79, loss = 0.95276842\n",
            "Validation score: 0.767904\n",
            "Iteration 80, loss = 0.94808632\n",
            "Validation score: 0.767740\n",
            "Iteration 81, loss = 0.94347783\n",
            "Validation score: 0.768561\n",
            "Iteration 82, loss = 0.93896076\n",
            "Validation score: 0.770696\n",
            "Iteration 83, loss = 0.93461697\n",
            "Validation score: 0.773489\n",
            "Iteration 84, loss = 0.93024661\n",
            "Validation score: 0.773653\n",
            "Iteration 85, loss = 0.92596250\n",
            "Validation score: 0.775460\n",
            "Iteration 86, loss = 0.92180211\n",
            "Validation score: 0.777267\n",
            "Iteration 87, loss = 0.91766880\n",
            "Validation score: 0.777924\n",
            "Iteration 88, loss = 0.91362931\n",
            "Validation score: 0.781209\n",
            "Iteration 89, loss = 0.90964798\n",
            "Validation score: 0.782523\n",
            "Iteration 90, loss = 0.90572372\n",
            "Validation score: 0.783837\n",
            "Iteration 91, loss = 0.90184454\n",
            "Validation score: 0.784166\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4PMRXKVjhb2b"
      },
      "source": [
        "**This code crashed after running for around 5 hours and we were not able to print the classification report. However, since the validation score is just at 78% eprcent after 91 iterations, we will not rerun it since it wont achieve the performance of the models being trained with Adam.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-brwl2BOwqC"
      },
      "source": [
        "classification_report(y_test, mlp_clf.predict(X_test_vec))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UMBqHGuqmiwF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ePp9RqvwpFzy"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jan-kreischer/UZH_ML4NLP/blob/main/Project-01/ex01_mlp_jan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lfUVMgBNottV"
      },
      "source": [
        "\n",
        "## hidden_layer_sizes=(200): configuration 5-8"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kD569-BptrHc"
      },
      "source": [
        "### Configuration 5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q-T9ReRRthN4",
        "outputId": "29737cbd-1fca-4b14-952c-d7ab73c97711"
      },
      "source": [
        "mlp_clf = MLPClassifier(early_stopping=True, hidden_layer_sizes=(200), solver='adam', activation='tanh', max_iter=100, verbose=True)\n",
        "mlp_clf.fit(X_train_vec, y_train)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 1.09069852\n",
            "Validation score: 0.898160\n",
            "Iteration 2, loss = 0.27471013\n",
            "Validation score: 0.921321\n",
            "Iteration 3, loss = 0.13070372\n",
            "Validation score: 0.925591\n",
            "Iteration 4, loss = 0.07119369\n",
            "Validation score: 0.925427\n",
            "Iteration 5, loss = 0.04386892\n",
            "Validation score: 0.924277\n",
            "Iteration 6, loss = 0.03021037\n",
            "Validation score: 0.921813\n",
            "Iteration 7, loss = 0.02308790\n",
            "Validation score: 0.918693\n",
            "Iteration 8, loss = 0.01875333\n",
            "Validation score: 0.920171\n",
            "Iteration 9, loss = 0.01624824\n",
            "Validation score: 0.920171\n",
            "Iteration 10, loss = 0.01456572\n",
            "Validation score: 0.921321\n",
            "Iteration 11, loss = 0.01326822\n",
            "Validation score: 0.921156\n",
            "Iteration 12, loss = 0.01228777\n",
            "Validation score: 0.920007\n",
            "Iteration 13, loss = 0.01157770\n",
            "Validation score: 0.920171\n",
            "Iteration 14, loss = 0.01090817\n",
            "Validation score: 0.921156\n",
            "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "MLPClassifier(activation='tanh', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
              "              beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
              "              hidden_layer_sizes=200, learning_rate='constant',\n",
              "              learning_rate_init=0.001, max_fun=15000, max_iter=100,\n",
              "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
              "              power_t=0.5, random_state=None, shuffle=True, solver='adam',\n",
              "              tol=0.0001, validation_fraction=0.1, verbose=True,\n",
              "              warm_start=False)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gyNs9cs-uUPK",
        "outputId": "483dbf10-9496-4828-ddab-89949e18eaa3"
      },
      "source": [
        "print(classification_report(y_test, mlp_clf.predict(X_test_vec)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "          ar       0.99      0.97      0.98       259\n",
            "      arlatn       0.00      0.00      0.00         3\n",
            "          az       1.00      1.00      1.00         4\n",
            "          bg       1.00      1.00      1.00         3\n",
            "          bn       1.00      1.00      1.00         3\n",
            "          bs       1.00      1.00      1.00         2\n",
            "          ca       0.00      0.00      0.00         1\n",
            "          cs       1.00      1.00      1.00         5\n",
            "          cy       1.00      1.00      1.00         1\n",
            "          da       1.00      0.80      0.89         5\n",
            "          de       1.00      0.54      0.70        24\n",
            "          dv       1.00      1.00      1.00         7\n",
            "          el       1.00      0.75      0.86         4\n",
            "          en       0.92      0.97      0.94      2255\n",
            "          es       0.94      0.94      0.94       789\n",
            "          et       1.00      1.00      1.00         4\n",
            "          eu       1.00      1.00      1.00         2\n",
            "          fa       1.00      0.67      0.80         3\n",
            "          fi       0.00      0.00      0.00         2\n",
            "          fr       0.97      0.87      0.92       124\n",
            "          gl       1.00      1.00      1.00         2\n",
            "          ha       1.00      1.00      1.00         5\n",
            "          he       1.00      1.00      1.00         3\n",
            "          hi       1.00      1.00      1.00         2\n",
            "      hilatn       1.00      0.50      0.67         2\n",
            "          hr       1.00      1.00      1.00         2\n",
            "          ht       1.00      1.00      1.00         2\n",
            "          hu       1.00      0.75      0.86         8\n",
            "          hy       1.00      1.00      1.00         3\n",
            "          id       0.89      0.92      0.90       353\n",
            "          is       1.00      1.00      1.00         4\n",
            "          it       1.00      0.72      0.84        47\n",
            "          ja       0.99      0.98      0.99      1336\n",
            "          km       1.00      1.00      1.00         6\n",
            "          ko       1.00      0.93      0.96        70\n",
            "      kolatn       1.00      1.00      1.00         5\n",
            "          la       1.00      1.00      1.00         5\n",
            "          lv       1.00      0.80      0.89         5\n",
            "          mk       1.00      1.00      1.00         4\n",
            "          mn       1.00      1.00      1.00         3\n",
            "          mr       1.00      1.00      1.00         5\n",
            "          ms       0.00      0.00      0.00        13\n",
            "          ne       1.00      1.00      1.00         6\n",
            "          nl       0.89      0.64      0.74        25\n",
            "          no       1.00      0.75      0.86         8\n",
            "          pl       1.00      0.67      0.80         9\n",
            "          ps       1.00      1.00      1.00         2\n",
            "      pslatn       1.00      1.00      1.00         1\n",
            "          pt       0.94      0.89      0.91       323\n",
            "          ro       1.00      1.00      1.00         1\n",
            "          ru       0.98      0.96      0.97       119\n",
            "          si       1.00      1.00      1.00         3\n",
            "          sk       1.00      1.00      1.00         1\n",
            "          sl       1.00      1.00      1.00         6\n",
            "          sq       1.00      1.00      1.00         1\n",
            "          sr       0.00      0.00      0.00         2\n",
            "          su       1.00      0.67      0.80         3\n",
            "          sv       1.00      0.57      0.73         7\n",
            "          sw       1.00      1.00      1.00         6\n",
            "          ta       1.00      1.00      1.00         5\n",
            "      talatn       1.00      1.00      1.00         6\n",
            "          th       0.98      0.95      0.97        64\n",
            "          tl       0.81      0.88      0.84        40\n",
            "          tn       1.00      1.00      1.00         4\n",
            "          tr       0.98      0.87      0.92        91\n",
            "          uk       1.00      0.88      0.93         8\n",
            "         und       0.68      0.70      0.69       606\n",
            "          ur       1.00      1.00      1.00         7\n",
            "      urlatn       1.00      0.50      0.67         2\n",
            "          vi       1.00      1.00      1.00         2\n",
            "          wo       1.00      1.00      1.00         6\n",
            "          xh       1.00      1.00      1.00         4\n",
            "          yo       1.00      1.00      1.00         3\n",
            "        zhcn       0.00      0.00      0.00         2\n",
            "        zhtw       1.00      1.00      1.00         3\n",
            "          zu       1.00      1.00      1.00         4\n",
            "\n",
            "    accuracy                           0.92      6765\n",
            "   macro avg       0.91      0.84      0.87      6765\n",
            "weighted avg       0.92      0.92      0.92      6765\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EwawZ5T9uF4x"
      },
      "source": [
        "### Configuration 6"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "loFg9Uget1Qe",
        "outputId": "1da37358-909c-46e2-df76-695b781483f6"
      },
      "source": [
        "mlp_clf = MLPClassifier(early_stopping=True, hidden_layer_sizes=(200), solver='adam', activation='relu', max_iter=100, verbose=True)\n",
        "mlp_clf.fit(X_train_vec, y_train)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 1.16928718\n",
            "Validation score: 0.896846\n",
            "Iteration 2, loss = 0.27827844\n",
            "Validation score: 0.924277\n",
            "Iteration 3, loss = 0.13075589\n",
            "Validation score: 0.931012\n",
            "Iteration 4, loss = 0.07191803\n",
            "Validation score: 0.931012\n",
            "Iteration 5, loss = 0.04476653\n",
            "Validation score: 0.931176\n",
            "Iteration 6, loss = 0.03102889\n",
            "Validation score: 0.930026\n",
            "Iteration 7, loss = 0.02358820\n",
            "Validation score: 0.929041\n",
            "Iteration 8, loss = 0.01942962\n",
            "Validation score: 0.929369\n",
            "Iteration 9, loss = 0.01665520\n",
            "Validation score: 0.929369\n",
            "Iteration 10, loss = 0.01488181\n",
            "Validation score: 0.928384\n",
            "Iteration 11, loss = 0.01358687\n",
            "Validation score: 0.928384\n",
            "Iteration 12, loss = 0.01254886\n",
            "Validation score: 0.928548\n",
            "Iteration 13, loss = 0.01174835\n",
            "Validation score: 0.927727\n",
            "Iteration 14, loss = 0.01116501\n",
            "Validation score: 0.928219\n",
            "Iteration 15, loss = 0.01050550\n",
            "Validation score: 0.927727\n",
            "Iteration 16, loss = 0.01003985\n",
            "Validation score: 0.928384\n",
            "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
              "              beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
              "              hidden_layer_sizes=200, learning_rate='constant',\n",
              "              learning_rate_init=0.001, max_fun=15000, max_iter=100,\n",
              "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
              "              power_t=0.5, random_state=None, shuffle=True, solver='adam',\n",
              "              tol=0.0001, validation_fraction=0.1, verbose=True,\n",
              "              warm_start=False)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E05Um7zGuW_C",
        "outputId": "092356f9-435b-45e2-b34c-6bf7a797df1d"
      },
      "source": [
        "print(classification_report(y_test, mlp_clf.predict(X_test_vec)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "          ar       0.98      0.99      0.99       283\n",
            "      arlatn       1.00      1.00      1.00         4\n",
            "          az       1.00      1.00      1.00         4\n",
            "          bg       1.00      1.00      1.00         7\n",
            "          bn       1.00      1.00      1.00         2\n",
            "          bs       1.00      0.80      0.89         5\n",
            "          ca       0.00      0.00      0.00         2\n",
            "          cs       1.00      1.00      1.00         3\n",
            "          cy       1.00      1.00      1.00         6\n",
            "          da       1.00      1.00      1.00         2\n",
            "          de       1.00      0.78      0.88        37\n",
            "          dv       1.00      1.00      1.00         3\n",
            "          el       1.00      1.00      1.00         1\n",
            "          en       0.93      0.97      0.95      2272\n",
            "          es       0.93      0.95      0.94       734\n",
            "          et       1.00      1.00      1.00         3\n",
            "          eu       1.00      1.00      1.00         7\n",
            "          fa       1.00      0.50      0.67         2\n",
            "          fi       1.00      0.50      0.67         2\n",
            "          fr       0.97      0.79      0.87       144\n",
            "          gl       1.00      1.00      1.00         3\n",
            "          ha       1.00      1.00      1.00         4\n",
            "          he       1.00      1.00      1.00         3\n",
            "          hi       1.00      1.00      1.00         1\n",
            "      hilatn       1.00      0.75      0.86         4\n",
            "          hr       1.00      1.00      1.00         3\n",
            "          ht       1.00      1.00      1.00         2\n",
            "          hu       1.00      0.86      0.92         7\n",
            "          hy       1.00      1.00      1.00         2\n",
            "          id       0.84      0.88      0.86       366\n",
            "          is       1.00      1.00      1.00         3\n",
            "          it       0.93      0.67      0.78        39\n",
            "          ja       0.99      0.98      0.99      1276\n",
            "      jalatn       1.00      1.00      1.00         6\n",
            "          jv       1.00      1.00      1.00         7\n",
            "          km       1.00      1.00      1.00         3\n",
            "          ko       1.00      0.73      0.84        48\n",
            "      kolatn       1.00      1.00      1.00         3\n",
            "          la       1.00      1.00      1.00         7\n",
            "          lv       1.00      1.00      1.00         5\n",
            "          mk       1.00      1.00      1.00         5\n",
            "          mn       1.00      1.00      1.00         7\n",
            "          mr       1.00      1.00      1.00         4\n",
            "          ms       0.50      0.10      0.17        20\n",
            "          ne       1.00      1.00      1.00         3\n",
            "          nl       1.00      0.77      0.87        26\n",
            "          no       1.00      1.00      1.00         2\n",
            "          pl       1.00      0.67      0.80        15\n",
            "          ps       1.00      1.00      1.00         5\n",
            "          pt       0.91      0.92      0.92       362\n",
            "          ro       1.00      0.67      0.80         6\n",
            "          ru       0.97      0.98      0.98       128\n",
            "          si       1.00      1.00      1.00         5\n",
            "          sk       1.00      1.00      1.00         3\n",
            "          sl       1.00      1.00      1.00         6\n",
            "          sq       1.00      1.00      1.00         5\n",
            "          sr       1.00      0.20      0.33         5\n",
            "          su       1.00      0.25      0.40         4\n",
            "          sv       1.00      0.44      0.62         9\n",
            "          sw       1.00      1.00      1.00         1\n",
            "          ta       1.00      1.00      1.00         7\n",
            "      talatn       1.00      1.00      1.00         2\n",
            "          th       1.00      1.00      1.00        51\n",
            "          tl       0.91      0.71      0.80        45\n",
            "          tn       1.00      1.00      1.00         4\n",
            "          tr       0.96      0.88      0.92        93\n",
            "          uk       1.00      0.86      0.92         7\n",
            "         und       0.64      0.65      0.65       596\n",
            "          ur       1.00      1.00      1.00         5\n",
            "      urlatn       1.00      0.60      0.75         5\n",
            "          vi       0.00      0.00      0.00         1\n",
            "          wo       1.00      1.00      1.00         2\n",
            "          xh       1.00      1.00      1.00         1\n",
            "          yo       1.00      1.00      1.00         2\n",
            "        zhtw       1.00      1.00      1.00         3\n",
            "          zu       1.00      1.00      1.00         5\n",
            "\n",
            "    accuracy                           0.92      6765\n",
            "   macro avg       0.95      0.87      0.89      6765\n",
            "weighted avg       0.92      0.92      0.91      6765\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RJJoxJWuotti"
      },
      "source": [
        "### Configuration 7"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2021-10-16T09:46:41.615001Z",
          "iopub.status.busy": "2021-10-16T09:46:41.614735Z",
          "iopub.status.idle": "2021-10-16T09:54:22.291069Z",
          "shell.execute_reply": "2021-10-16T09:54:22.289706Z",
          "shell.execute_reply.started": "2021-10-16T09:46:41.614971Z"
        },
        "id": "bubkQtE-iVyI",
        "outputId": "013903ef-bf6c-45e1-c6aa-d2e4c78320f5"
      },
      "source": [
        "mlp_clf = MLPClassifier(early_stopping=True, hidden_layer_sizes=(200), solver='sgd', activation='tanh', max_iter=100, verbose=True)\n",
        "mlp_clf.fit(X_train_vec, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 3.70249981\n",
            "Validation score: 0.343627\n",
            "Iteration 2, loss = 2.69717160\n",
            "Validation score: 0.343627\n",
            "Iteration 3, loss = 2.39582595\n",
            "Validation score: 0.343627\n",
            "Iteration 4, loss = 2.26983137\n",
            "Validation score: 0.343627\n",
            "Iteration 5, loss = 2.20258270\n",
            "Validation score: 0.343627\n",
            "Iteration 6, loss = 2.15363711\n",
            "Validation score: 0.386170\n",
            "Iteration 7, loss = 2.10856486\n",
            "Validation score: 0.485381\n",
            "Iteration 8, loss = 2.06354278\n",
            "Validation score: 0.509198\n",
            "Iteration 9, loss = 2.01797672\n",
            "Validation score: 0.521353\n",
            "Iteration 10, loss = 1.97237272\n",
            "Validation score: 0.521353\n",
            "Iteration 11, loss = 1.92752119\n",
            "Validation score: 0.520368\n",
            "Iteration 12, loss = 1.88398228\n",
            "Validation score: 0.518725\n",
            "Iteration 13, loss = 1.84233862\n",
            "Validation score: 0.516919\n",
            "Iteration 14, loss = 1.80273953\n",
            "Validation score: 0.517083\n",
            "Iteration 15, loss = 1.76505337\n",
            "Validation score: 0.517576\n",
            "Iteration 16, loss = 1.72908061\n",
            "Validation score: 0.518561\n",
            "Iteration 17, loss = 1.69467793\n",
            "Validation score: 0.521353\n",
            "Iteration 18, loss = 1.66162981\n",
            "Validation score: 0.526281\n",
            "Iteration 19, loss = 1.62971276\n",
            "Validation score: 0.535808\n",
            "Iteration 20, loss = 1.59892563\n",
            "Validation score: 0.550263\n",
            "Iteration 21, loss = 1.56920564\n",
            "Validation score: 0.570795\n",
            "Iteration 22, loss = 1.54057397\n",
            "Validation score: 0.593298\n",
            "Iteration 23, loss = 1.51304759\n",
            "Validation score: 0.602168\n",
            "Iteration 24, loss = 1.48655961\n",
            "Validation score: 0.610217\n",
            "Iteration 25, loss = 1.46129017\n",
            "Validation score: 0.621222\n",
            "Iteration 26, loss = 1.43709952\n",
            "Validation score: 0.628449\n",
            "Iteration 27, loss = 1.41408361\n",
            "Validation score: 0.636005\n",
            "Iteration 28, loss = 1.39223118\n",
            "Validation score: 0.642247\n",
            "Iteration 29, loss = 1.37143819\n",
            "Validation score: 0.648982\n",
            "Iteration 30, loss = 1.35177536\n",
            "Validation score: 0.653581\n",
            "Iteration 31, loss = 1.33306992\n",
            "Validation score: 0.662122\n",
            "Iteration 32, loss = 1.31530034\n",
            "Validation score: 0.666557\n",
            "Iteration 33, loss = 1.29845560\n",
            "Validation score: 0.674934\n",
            "Iteration 34, loss = 1.28241096\n",
            "Validation score: 0.680848\n",
            "Iteration 35, loss = 1.26716929\n",
            "Validation score: 0.685283\n",
            "Iteration 36, loss = 1.25255334\n",
            "Validation score: 0.688568\n",
            "Iteration 37, loss = 1.23862458\n",
            "Validation score: 0.693495\n",
            "Iteration 38, loss = 1.22528452\n",
            "Validation score: 0.698095\n",
            "Iteration 39, loss = 1.21250156\n",
            "Validation score: 0.703187\n",
            "Iteration 40, loss = 1.20020462\n",
            "Validation score: 0.705322\n",
            "Iteration 41, loss = 1.18839254\n",
            "Validation score: 0.710578\n",
            "Iteration 42, loss = 1.17697136\n",
            "Validation score: 0.711071\n",
            "Iteration 43, loss = 1.16600295\n",
            "Validation score: 0.716820\n",
            "Iteration 44, loss = 1.15537412\n",
            "Validation score: 0.720598\n",
            "Iteration 45, loss = 1.14509963\n",
            "Validation score: 0.722733\n",
            "Iteration 46, loss = 1.13515941\n",
            "Validation score: 0.725033\n",
            "Iteration 47, loss = 1.12551359\n",
            "Validation score: 0.727497\n",
            "Iteration 48, loss = 1.11621460\n",
            "Validation score: 0.729796\n",
            "Iteration 49, loss = 1.10709397\n",
            "Validation score: 0.730946\n",
            "Iteration 50, loss = 1.09828425\n",
            "Validation score: 0.732917\n",
            "Iteration 51, loss = 1.08971079\n",
            "Validation score: 0.735053\n",
            "Iteration 52, loss = 1.08141290\n",
            "Validation score: 0.736859\n",
            "Iteration 53, loss = 1.07331725\n",
            "Validation score: 0.737845\n",
            "Iteration 54, loss = 1.06540585\n",
            "Validation score: 0.739159\n",
            "Iteration 55, loss = 1.05774942\n",
            "Validation score: 0.743430\n",
            "Iteration 56, loss = 1.05028504\n",
            "Validation score: 0.743594\n",
            "Iteration 57, loss = 1.04301203\n",
            "Validation score: 0.746386\n",
            "Iteration 58, loss = 1.03590004\n",
            "Validation score: 0.748522\n",
            "Iteration 59, loss = 1.02902258\n",
            "Validation score: 0.749507\n",
            "Iteration 60, loss = 1.02226838\n",
            "Validation score: 0.749343\n",
            "Iteration 61, loss = 1.01566995\n",
            "Validation score: 0.751150\n",
            "Iteration 62, loss = 1.00925489\n",
            "Validation score: 0.755256\n",
            "Iteration 63, loss = 1.00300600\n",
            "Validation score: 0.754271\n",
            "Iteration 64, loss = 0.99688749\n",
            "Validation score: 0.757227\n",
            "Iteration 65, loss = 0.99093246\n",
            "Validation score: 0.758541\n",
            "Iteration 66, loss = 0.98510924\n",
            "Validation score: 0.759034\n",
            "Iteration 67, loss = 0.97940174\n",
            "Validation score: 0.761662\n",
            "Iteration 68, loss = 0.97383430\n",
            "Validation score: 0.761991\n",
            "Iteration 69, loss = 0.96837912\n",
            "Validation score: 0.763469\n",
            "Iteration 70, loss = 0.96306066\n",
            "Validation score: 0.765769\n",
            "Iteration 71, loss = 0.95783286\n",
            "Validation score: 0.767740\n",
            "Iteration 72, loss = 0.95273305\n",
            "Validation score: 0.768725\n",
            "Iteration 73, loss = 0.94772958\n",
            "Validation score: 0.771682\n",
            "Iteration 74, loss = 0.94286595\n",
            "Validation score: 0.772011\n",
            "Iteration 75, loss = 0.93804390\n",
            "Validation score: 0.773653\n",
            "Iteration 76, loss = 0.93331464\n",
            "Validation score: 0.773325\n",
            "Iteration 77, loss = 0.92869261\n",
            "Validation score: 0.774639\n",
            "Iteration 78, loss = 0.92422148\n",
            "Validation score: 0.777267\n",
            "Iteration 79, loss = 0.91974878\n",
            "Validation score: 0.777760\n",
            "Iteration 80, loss = 0.91539317\n",
            "Validation score: 0.779895\n",
            "Iteration 81, loss = 0.91108623\n",
            "Validation score: 0.780223\n",
            "Iteration 82, loss = 0.90688962\n",
            "Validation score: 0.782359\n",
            "Iteration 83, loss = 0.90274567\n",
            "Validation score: 0.782852\n",
            "Iteration 84, loss = 0.89867988\n",
            "Validation score: 0.783673\n",
            "Iteration 85, loss = 0.89467521\n",
            "Validation score: 0.784494\n",
            "Iteration 86, loss = 0.89073850\n",
            "Validation score: 0.784658\n",
            "Iteration 87, loss = 0.88687711\n",
            "Validation score: 0.786958\n",
            "Iteration 88, loss = 0.88305621\n",
            "Validation score: 0.788272\n",
            "Iteration 89, loss = 0.87926802\n",
            "Validation score: 0.790407\n",
            "Iteration 90, loss = 0.87557077\n",
            "Validation score: 0.791229\n",
            "Iteration 91, loss = 0.87191952\n",
            "Validation score: 0.792050\n",
            "Iteration 92, loss = 0.86835515\n",
            "Validation score: 0.792871\n",
            "Iteration 93, loss = 0.86478605\n",
            "Validation score: 0.792707\n",
            "Iteration 94, loss = 0.86131876\n",
            "Validation score: 0.793693\n",
            "Iteration 95, loss = 0.85788630\n",
            "Validation score: 0.794842\n",
            "Iteration 96, loss = 0.85448165\n",
            "Validation score: 0.796978\n",
            "Iteration 97, loss = 0.85111729\n",
            "Validation score: 0.797470\n",
            "Iteration 98, loss = 0.84784344\n",
            "Validation score: 0.798456\n",
            "Iteration 99, loss = 0.84456882\n",
            "Validation score: 0.798949\n",
            "Iteration 100, loss = 0.84134895\n",
            "Validation score: 0.799770\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "MLPClassifier(activation='tanh', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
              "              beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
              "              hidden_layer_sizes=200, learning_rate='constant',\n",
              "              learning_rate_init=0.001, max_fun=15000, max_iter=100,\n",
              "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
              "              power_t=0.5, random_state=None, shuffle=True, solver='sgd',\n",
              "              tol=0.0001, validation_fraction=0.1, verbose=True,\n",
              "              warm_start=False)"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.status.busy": "2021-10-16T09:54:22.292515Z",
          "iopub.status.idle": "2021-10-16T09:54:22.293197Z",
          "shell.execute_reply": "2021-10-16T09:54:22.292949Z",
          "shell.execute_reply.started": "2021-10-16T09:54:22.292922Z"
        },
        "id": "UnGrrGK2iVyI",
        "outputId": "4adfd1b3-2606-4f3b-fbcd-7fd35556e91a"
      },
      "source": [
        "print(classification_report(y_test, mlp_clf.predict(X_test_vec)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "          ar       0.93      0.96      0.95       255\n",
            "      arlatn       0.00      0.00      0.00         6\n",
            "          az       0.00      0.00      0.00         3\n",
            "          bg       0.00      0.00      0.00         3\n",
            "          bn       0.00      0.00      0.00         3\n",
            "          bs       0.00      0.00      0.00         4\n",
            "          ca       0.00      0.00      0.00         3\n",
            "          cs       0.00      0.00      0.00         5\n",
            "          cy       0.00      0.00      0.00         5\n",
            "          da       0.00      0.00      0.00         3\n",
            "          de       0.00      0.00      0.00        21\n",
            "          dv       0.00      0.00      0.00         1\n",
            "          el       0.00      0.00      0.00         2\n",
            "          en       0.86      0.96      0.91      2358\n",
            "          es       0.77      0.92      0.84       738\n",
            "          et       0.00      0.00      0.00         7\n",
            "          eu       0.00      0.00      0.00         6\n",
            "          fa       0.00      0.00      0.00         3\n",
            "          fi       0.00      0.00      0.00         1\n",
            "          fr       0.00      0.00      0.00       114\n",
            "          gl       0.00      0.00      0.00         3\n",
            "          ha       0.00      0.00      0.00         2\n",
            "          he       0.00      0.00      0.00         3\n",
            "          hi       0.00      0.00      0.00         3\n",
            "      hilatn       0.00      0.00      0.00         5\n",
            "          hr       0.00      0.00      0.00         4\n",
            "          ht       0.00      0.00      0.00         5\n",
            "          hu       0.00      0.00      0.00         6\n",
            "          id       0.64      0.79      0.71       345\n",
            "          is       0.00      0.00      0.00         6\n",
            "          it       0.00      0.00      0.00        50\n",
            "          ja       0.91      0.97      0.94      1297\n",
            "      jalatn       0.00      0.00      0.00         3\n",
            "          jv       0.00      0.00      0.00         5\n",
            "          km       0.00      0.00      0.00         5\n",
            "          ko       0.00      0.00      0.00        50\n",
            "      kolatn       0.00      0.00      0.00         1\n",
            "          la       0.00      0.00      0.00         4\n",
            "          lv       0.00      0.00      0.00         6\n",
            "          mk       0.00      0.00      0.00         3\n",
            "          mn       0.00      0.00      0.00         3\n",
            "          mr       0.00      0.00      0.00         5\n",
            "          ms       0.00      0.00      0.00        17\n",
            "          ne       0.00      0.00      0.00         5\n",
            "          nl       0.00      0.00      0.00        27\n",
            "          no       0.00      0.00      0.00         3\n",
            "          pl       0.00      0.00      0.00        11\n",
            "          ps       0.00      0.00      0.00         9\n",
            "      pslatn       0.00      0.00      0.00         3\n",
            "          pt       0.88      0.65      0.75       388\n",
            "          ro       0.00      0.00      0.00         6\n",
            "          ru       0.90      0.89      0.89       110\n",
            "          si       0.00      0.00      0.00         1\n",
            "          sk       0.00      0.00      0.00         6\n",
            "          sl       0.00      0.00      0.00         4\n",
            "          sq       0.00      0.00      0.00         6\n",
            "          sr       0.00      0.00      0.00         3\n",
            "          su       0.00      0.00      0.00         4\n",
            "          sv       0.00      0.00      0.00         7\n",
            "          sw       0.00      0.00      0.00         4\n",
            "          ta       0.00      0.00      0.00         2\n",
            "      talatn       0.00      0.00      0.00         5\n",
            "          th       0.00      0.00      0.00        59\n",
            "          tl       0.00      0.00      0.00        50\n",
            "          tn       0.00      0.00      0.00         2\n",
            "          tr       0.00      0.00      0.00        90\n",
            "          uk       0.00      0.00      0.00         5\n",
            "         und       0.40      0.56      0.47       550\n",
            "          ur       0.00      0.00      0.00         4\n",
            "      urlatn       0.00      0.00      0.00         6\n",
            "          vi       0.00      0.00      0.00         3\n",
            "          wo       0.00      0.00      0.00         1\n",
            "          xh       0.00      0.00      0.00         2\n",
            "          yo       0.00      0.00      0.00         6\n",
            "        zhcn       0.00      0.00      0.00         3\n",
            "        zhtw       0.00      0.00      0.00         6\n",
            "          zu       0.00      0.00      0.00         2\n",
            "\n",
            "    accuracy                           0.80      6765\n",
            "   macro avg       0.08      0.09      0.08      6765\n",
            "weighted avg       0.72      0.80      0.76      6765\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N9NJk_UluMvZ"
      },
      "source": [
        "### Configuration 8"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ilsQFkyKuB-U",
        "outputId": "301684fa-ecde-44bf-8f4b-4ec7f0bf03e4"
      },
      "source": [
        "mlp_clf = MLPClassifier(early_stopping=True, hidden_layer_sizes=(200), solver='sgd', activation='relu', max_iter=100, verbose=True)\n",
        "mlp_clf.fit(X_train_vec, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 3.98300187\n",
            "Validation score: 0.339520\n",
            "Iteration 2, loss = 3.03748377\n",
            "Validation score: 0.339520\n",
            "Iteration 3, loss = 2.52303243\n",
            "Validation score: 0.339520\n",
            "Iteration 4, loss = 2.33395189\n",
            "Validation score: 0.339520\n",
            "Iteration 5, loss = 2.23689899\n",
            "Validation score: 0.339520\n",
            "Iteration 6, loss = 2.17713531\n",
            "Validation score: 0.341820\n",
            "Iteration 7, loss = 2.12898423\n",
            "Validation score: 0.431012\n",
            "Iteration 8, loss = 2.08270709\n",
            "Validation score: 0.502628\n",
            "Iteration 9, loss = 2.03630077\n",
            "Validation score: 0.518890\n",
            "Iteration 10, loss = 1.98986490\n",
            "Validation score: 0.521189\n",
            "Iteration 11, loss = 1.94401979\n",
            "Validation score: 0.521025\n",
            "Iteration 12, loss = 1.89970961\n",
            "Validation score: 0.520696\n",
            "Iteration 13, loss = 1.85725869\n",
            "Validation score: 0.519547\n",
            "Iteration 14, loss = 1.81703284\n",
            "Validation score: 0.519218\n",
            "Iteration 15, loss = 1.77893385\n",
            "Validation score: 0.518725\n",
            "Iteration 16, loss = 1.74274838\n",
            "Validation score: 0.520204\n",
            "Iteration 17, loss = 1.70825634\n",
            "Validation score: 0.522175\n",
            "Iteration 18, loss = 1.67517703\n",
            "Validation score: 0.526610\n",
            "Iteration 19, loss = 1.64329366\n",
            "Validation score: 0.538108\n",
            "Iteration 20, loss = 1.61260493\n",
            "Validation score: 0.546978\n",
            "Iteration 21, loss = 1.58296134\n",
            "Validation score: 0.560775\n",
            "Iteration 22, loss = 1.55433587\n",
            "Validation score: 0.575230\n",
            "Iteration 23, loss = 1.52672923\n",
            "Validation score: 0.591656\n",
            "Iteration 24, loss = 1.50018910\n",
            "Validation score: 0.606767\n",
            "Iteration 25, loss = 1.47468322\n",
            "Validation score: 0.618265\n",
            "Iteration 26, loss = 1.45025312\n",
            "Validation score: 0.623850\n",
            "Iteration 27, loss = 1.42696090\n",
            "Validation score: 0.627792\n",
            "Iteration 28, loss = 1.40474078\n",
            "Validation score: 0.635677\n",
            "Iteration 29, loss = 1.38355712\n",
            "Validation score: 0.640604\n",
            "Iteration 30, loss = 1.36343794\n",
            "Validation score: 0.645696\n",
            "Iteration 31, loss = 1.34436424\n",
            "Validation score: 0.649639\n",
            "Iteration 32, loss = 1.32621072\n",
            "Validation score: 0.653252\n",
            "Iteration 33, loss = 1.30893355\n",
            "Validation score: 0.657359\n",
            "Iteration 34, loss = 1.29252028\n",
            "Validation score: 0.663765\n",
            "Iteration 35, loss = 1.27691213\n",
            "Validation score: 0.671813\n",
            "Iteration 36, loss = 1.26202509\n",
            "Validation score: 0.678384\n",
            "Iteration 37, loss = 1.24780959\n",
            "Validation score: 0.681505\n",
            "Iteration 38, loss = 1.23421558\n",
            "Validation score: 0.686104\n",
            "Iteration 39, loss = 1.22117372\n",
            "Validation score: 0.688568\n",
            "Iteration 40, loss = 1.20867471\n",
            "Validation score: 0.693824\n",
            "Iteration 41, loss = 1.19669775\n",
            "Validation score: 0.697109\n",
            "Iteration 42, loss = 1.18512879\n",
            "Validation score: 0.701873\n",
            "Iteration 43, loss = 1.17395944\n",
            "Validation score: 0.705486\n",
            "Iteration 44, loss = 1.16320444\n",
            "Validation score: 0.708443\n",
            "Iteration 45, loss = 1.15284571\n",
            "Validation score: 0.710250\n",
            "Iteration 46, loss = 1.14277769\n",
            "Validation score: 0.715342\n",
            "Iteration 47, loss = 1.13301892\n",
            "Validation score: 0.717148\n",
            "Iteration 48, loss = 1.12355959\n",
            "Validation score: 0.720105\n",
            "Iteration 49, loss = 1.11441324\n",
            "Validation score: 0.723390\n",
            "Iteration 50, loss = 1.10550422\n",
            "Validation score: 0.726511\n",
            "Iteration 51, loss = 1.09684978\n",
            "Validation score: 0.729139\n",
            "Iteration 52, loss = 1.08842390\n",
            "Validation score: 0.731110\n",
            "Iteration 53, loss = 1.08023785\n",
            "Validation score: 0.732917\n",
            "Iteration 54, loss = 1.07225205\n",
            "Validation score: 0.734231\n",
            "Iteration 55, loss = 1.06448317\n",
            "Validation score: 0.735545\n",
            "Iteration 56, loss = 1.05690499\n",
            "Validation score: 0.737024\n",
            "Iteration 57, loss = 1.04955022\n",
            "Validation score: 0.738995\n",
            "Iteration 58, loss = 1.04233262\n",
            "Validation score: 0.740966\n",
            "Iteration 59, loss = 1.03536738\n",
            "Validation score: 0.743101\n",
            "Iteration 60, loss = 1.02851266\n",
            "Validation score: 0.745072\n",
            "Iteration 61, loss = 1.02183352\n",
            "Validation score: 0.745237\n",
            "Iteration 62, loss = 1.01530706\n",
            "Validation score: 0.747700\n",
            "Iteration 63, loss = 1.00895242\n",
            "Validation score: 0.748193\n",
            "Iteration 64, loss = 1.00274792\n",
            "Validation score: 0.751807\n",
            "Iteration 65, loss = 0.99668398\n",
            "Validation score: 0.751478\n",
            "Iteration 66, loss = 0.99078650\n",
            "Validation score: 0.752135\n",
            "Iteration 67, loss = 0.98500460\n",
            "Validation score: 0.753614\n",
            "Iteration 68, loss = 0.97932487\n",
            "Validation score: 0.756242\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NMtrpZF1pzjq"
      },
      "source": [
        "**The colab session crashed before we get the result after running for 10 hours.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HwPK_skSyzA7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4wDuqlBSDZd2"
      },
      "source": [
        "## hidden_layer_sizes=(500)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SarGO22CEKAB"
      },
      "source": [
        "### Configuration 9\n",
        "\n",
        "**We wanted to test the performance of a MLP being trained with adam and relu and one hidden layer with 500 neurons since, adam and relu performed better than sgd and tanh. We could see that the performance is similar to the same model with 100 neurons in the hidden layer.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uuK8Loq39fnj",
        "outputId": "e16588ac-ed93-47fb-e182-76e101ec990e"
      },
      "source": [
        "mlp_clf = MLPClassifier(early_stopping=True, hidden_layer_sizes=(500), solver='adam', activation='relu', max_iter=50, verbose=True)\n",
        "mlp_clf.fit(X_train_vec, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 0.89183017\n",
            "Validation score: 0.906866\n",
            "Iteration 2, loss = 0.17527408\n",
            "Validation score: 0.919514\n",
            "Iteration 3, loss = 0.07068142\n",
            "Validation score: 0.921649\n",
            "Iteration 4, loss = 0.03743430\n",
            "Validation score: 0.919842\n",
            "Iteration 5, loss = 0.02444688\n",
            "Validation score: 0.915572\n",
            "Iteration 6, loss = 0.01876033\n",
            "Validation score: 0.919678\n",
            "Iteration 7, loss = 0.01559447\n",
            "Validation score: 0.918528\n",
            "Iteration 8, loss = 0.01382175\n",
            "Validation score: 0.917214\n",
            "Iteration 9, loss = 0.01289217\n",
            "Validation score: 0.918857\n",
            "Iteration 10, loss = 0.01175382\n",
            "Validation score: 0.919842\n",
            "Iteration 11, loss = 0.01099969\n",
            "Validation score: 0.920992\n",
            "Iteration 12, loss = 0.01045910\n",
            "Validation score: 0.919514\n",
            "Iteration 13, loss = 0.00997286\n",
            "Validation score: 0.917378\n",
            "Iteration 14, loss = 0.00973240\n",
            "Validation score: 0.921156\n",
            "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
              "              beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
              "              hidden_layer_sizes=500, learning_rate='constant',\n",
              "              learning_rate_init=0.001, max_fun=15000, max_iter=50,\n",
              "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
              "              power_t=0.5, random_state=None, shuffle=True, solver='adam',\n",
              "              tol=0.0001, validation_fraction=0.1, verbose=True,\n",
              "              warm_start=False)"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vVzdww4E9ouh",
        "outputId": "28fa4245-497f-4f2d-d357-fd530c210646"
      },
      "source": [
        "print(classification_report(y_test, mlp_clf.predict(X_test_vec)))classification_report(y_test, mlp_clf.predict(X_test_vec))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "          ar       0.98      0.98      0.98       299\n",
            "      arlatn       1.00      0.67      0.80         3\n",
            "          az       1.00      1.00      1.00         6\n",
            "          bg       1.00      1.00      1.00         4\n",
            "          bn       1.00      1.00      1.00         5\n",
            "          bs       1.00      0.80      0.89        10\n",
            "          ca       0.00      0.00      0.00         2\n",
            "          cs       1.00      1.00      1.00         6\n",
            "          cy       1.00      1.00      1.00         1\n",
            "          da       1.00      0.75      0.86         4\n",
            "          de       1.00      0.83      0.91        24\n",
            "          dv       1.00      1.00      1.00         7\n",
            "          el       1.00      1.00      1.00         4\n",
            "          en       0.94      0.96      0.95      2298\n",
            "          es       0.94      0.94      0.94       757\n",
            "          et       1.00      1.00      1.00         3\n",
            "          eu       1.00      1.00      1.00         5\n",
            "          fa       1.00      0.25      0.40         4\n",
            "          fi       1.00      1.00      1.00         2\n",
            "          fr       0.96      0.82      0.88       117\n",
            "          gl       1.00      1.00      1.00         3\n",
            "          ha       1.00      1.00      1.00         2\n",
            "          he       1.00      0.71      0.83         7\n",
            "          hi       1.00      0.67      0.80         3\n",
            "      hilatn       1.00      0.67      0.80         6\n",
            "          hr       0.80      1.00      0.89         4\n",
            "          ht       1.00      1.00      1.00         4\n",
            "          hu       1.00      0.75      0.86         8\n",
            "          hy       1.00      1.00      1.00         2\n",
            "          id       0.88      0.89      0.88       365\n",
            "          is       1.00      1.00      1.00         4\n",
            "          it       0.97      0.81      0.88        42\n",
            "          ja       0.99      0.99      0.99      1252\n",
            "      jalatn       1.00      1.00      1.00         2\n",
            "          jv       0.00      0.00      0.00         2\n",
            "          km       1.00      1.00      1.00         6\n",
            "          ko       0.98      0.85      0.91        54\n",
            "      kolatn       1.00      1.00      1.00         2\n",
            "          la       1.00      1.00      1.00         4\n",
            "          lv       1.00      1.00      1.00         9\n",
            "          mk       1.00      1.00      1.00         7\n",
            "          mn       1.00      1.00      1.00         6\n",
            "          mr       1.00      1.00      1.00         6\n",
            "          ms       0.38      0.21      0.27        14\n",
            "          ne       1.00      1.00      1.00         5\n",
            "          nl       1.00      0.82      0.90        17\n",
            "          no       1.00      1.00      1.00         7\n",
            "          pl       1.00      0.78      0.88        18\n",
            "          ps       1.00      1.00      1.00         7\n",
            "      pslatn       1.00      1.00      1.00         3\n",
            "          pt       0.93      0.91      0.92       362\n",
            "          ro       1.00      0.88      0.93         8\n",
            "          ru       0.98      0.96      0.97       109\n",
            "          si       1.00      1.00      1.00         6\n",
            "          sk       1.00      1.00      1.00         2\n",
            "          sq       1.00      1.00      1.00         2\n",
            "          sr       1.00      0.25      0.40         4\n",
            "          su       1.00      1.00      1.00         6\n",
            "          sv       1.00      1.00      1.00         5\n",
            "          sw       1.00      1.00      1.00         3\n",
            "          ta       1.00      1.00      1.00         6\n",
            "      talatn       1.00      1.00      1.00         5\n",
            "          th       0.98      0.93      0.96        60\n",
            "          tl       0.91      0.74      0.82        42\n",
            "          tn       1.00      1.00      1.00         4\n",
            "          tr       0.97      0.87      0.92        90\n",
            "          uk       1.00      0.86      0.92         7\n",
            "         und       0.65      0.71      0.68       576\n",
            "          ur       1.00      1.00      1.00         8\n",
            "      urlatn       1.00      0.50      0.67         6\n",
            "          vi       1.00      1.00      1.00         1\n",
            "          wo       1.00      1.00      1.00         3\n",
            "          xh       1.00      1.00      1.00         2\n",
            "          yo       1.00      1.00      1.00         4\n",
            "        zhcn       0.00      0.00      0.00         1\n",
            "        zhtw       1.00      1.00      1.00         6\n",
            "          zu       1.00      1.00      1.00         5\n",
            "\n",
            "    accuracy                           0.92      6765\n",
            "   macro avg       0.94      0.87      0.89      6765\n",
            "weighted avg       0.93      0.92      0.92      6765\n",
            "\n"
          ]
        }
      ]
    }
  ]
}